{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bc6fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import fitz\n",
    "import re\n",
    "import textwrap\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Local Paths\n",
    "# MODEL_PATH =\"/Users/sir/Downloads/HuggingFace/sentence_transformer/intfloat_e5-large-v2\"\n",
    "# LLM_PATH = \"/Users/sir/Downloads/HuggingFace/LLM/meta-Llama-3.1-8B-Instruct\"\n",
    "LLM_PATH = \"/Users/sir/Downloads/HuggingFace/LLM/meta-Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# use mps if available, else cuda, else cpu\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14feb3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Generator: /Users/sir/Downloads/HuggingFace/LLM/meta-Llama-3.2-1B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# --- MODEL 1: THE \"GENERATOR\" (Llama 3.1 for summarizing) ---\n",
    "print(f\"Loading Generator: {LLM_PATH}\")\n",
    "\n",
    "# This line will now work correctly\n",
    "generator_model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLM_PATH, \n",
    "    device_map=DEVICE, # Automatically map to your M3 GPU\n",
    "    dtype=torch.bfloat16, # Use bfloat16 for M3\n",
    "    trust_remote_code=True\n",
    ")\n",
    "generator_tokenizer = AutoTokenizer.from_pretrained(LLM_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227890b",
   "metadata": {},
   "source": [
    "### Summarization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9d2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"We survey 146 papers analyzing “bias” in\n",
    "NLP systems, finding that their motivations\n",
    "are often vague, inconsistent, and lacking\n",
    "in normative reasoning, despite the fact that\n",
    "analyzing “bias” is an inherently normative\n",
    "process. We further find that these papers’\n",
    "proposed quantitative techniques for measuring\n",
    "or mitigating “bias” are poorly matched to\n",
    "their motivations and do not engage with the\n",
    "relevant literature outside of NLP. Based on\n",
    "these findings, we describe the beginnings of a\n",
    "path forward by proposing three recommendations\n",
    "that should guide work analyzing “bias”\n",
    "in NLP systems. These recommendations rest\n",
    "on a greater recognition of the relationships\n",
    "between language and social hierarchies,\n",
    "encouraging researchers and practitioners\n",
    "to articulate their conceptualizations of\n",
    "“bias”—i.e., what kinds of system behaviors\n",
    "are harmful, in what ways, to whom, and why,\n",
    "as well as the normative reasoning underlying\n",
    "these statements—and to center work around\n",
    "the lived experiences of members of communities\n",
    "affected by NLP systems, while interrogating\n",
    "and reimagining the power relations\n",
    "between technologists and such communities.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2845a767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GENERATED SUMMARY ---\n",
      "Here is a concise summary of the text:  Researchers in the field of Natural\n",
      "Language Processing (NLP) have found that many papers on bias in NLP systems are\n",
      "vague, inconsistent, and lack a clear understanding of what constitutes bias. To\n",
      "improve the field, the authors propose three recommendations: (1) researchers\n",
      "should articulate their conceptualizations of bias and its impact on\n",
      "communities, (2) work should center on the lived experiences of those affected\n",
      "by NLP systems, and (3) researchers should interrogate and reimagine the power\n",
      "dynamics between technologists and the communities they serve.\n"
     ]
    }
   ],
   "source": [
    "# prompt construction\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Clearly summarize the following text in one concise paragraph:\n",
    "\n",
    "{text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "input = generator_tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "\n",
    "# Generate text\n",
    "with torch.no_grad():\n",
    "    outputs = generator_model.generate(\n",
    "        **input,\n",
    "        max_new_tokens=700,         # Number of tokens to generate\n",
    "        do_sample=True,             # Enable sampling for more natural output\n",
    "        temperature=0.06,            # Controls randomness\n",
    "        top_p=0.9,                  # Nucleus sampling\n",
    "        pad_token_id=generator_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# 1. Decode the raw text\n",
    "# We only want the generated part, not the input prompt\n",
    "output_token_ids = outputs[0][len(input['input_ids'][0]):]\n",
    "raw_output = generator_tokenizer.decode(output_token_ids, skip_special_tokens=True)\n",
    "\n",
    "# 2. Clean the output (it might have extra spaces)\n",
    "response_only = raw_output.strip()\n",
    "\n",
    "# 3. Wrap and print the final, correct summary\n",
    "formatted_text = textwrap.fill(response_only, width=80)\n",
    "print(\"\\n--- GENERATED SUMMARY ---\")\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5fd1675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GENERATED SUMMARY ---\n",
      "Here is a concise summary of the text:  A UPS MD-11 plane crashed shortly after\n",
      "take-off near Louisville, Kentucky, airport, killing three crew members and\n",
      "injuring others. The plane, which was carrying over 2 million packages, was\n",
      "headed to Honolulu International Airport when it crashed, and authorities are\n",
      "investigating the cause. The plane was manufactured by Boeing and was originally\n",
      "designed for passenger flights, but was converted to a freighter after fuel\n",
      "costs increased.\n"
     ]
    }
   ],
   "source": [
    "# --- Your Original Text (This is what E5 would find) ---\n",
    "text = \"\"\"\n",
    "A UPS MD-11 plane crashed shortly after take-off near the Louisville, Kentucky, airport, according to the Federal Aviation Administration. UPS Flight 2976 crashed \n",
    "just after 5 p.m. local time and was headed to Daniel K. Inouye International Airport in Honolulu, according to a statement from the FAA, which is investigating the crash \n",
    "along with the National Transportation Safety Board. The NTSB will lead the investigation, the FAA said Tuesday.\n",
    "Three crewmembers were on the plane, according to a statement from UPS that said in part, “At this time, we have not confirmed any injuries/casualties.”\n",
    "Louisville Metro Police Department and other agencies are responding to the crash, LMPD said in an X post. Injuries have been reported, police said.\n",
    "A massive plume of black smoke is rising not far from the tarmac at Louisville Muhammad Ali International Airport, videos from CNN affiliate WAVE show.\n",
    "Louisville Muhammad Ali International Airport is the worldwide air hub for UPS. The company’s Worldport is more than 5 million square feet where more \n",
    "than 12,000 UPS employees process more than two million packages a day, according to the company.\n",
    "A shelter-in-place has been issued for all locations within 5 miles of the airport, police added.\n",
    "“LMPD and multiple other agencies are responding to reports of a plan crash near Fern Valley and Grade Lane,” the post said. “Grade lane will be \n",
    "closed indefinitely between Stooges and Crittenden.” The McDonnell Douglas MD-11F is a freight transport aircraft manufactured originally by McDonnell \n",
    "Douglas and later by Boeing. The aircraft is primarily flown by FedEx Express, Lufthansa Cargo and UPS Airlines for cargo.\n",
    "The plane also served as a popular wide-bodied passenger airplane after it was first flown in 1990. The aircraft involved in Tuesday’s crash was built in 1991.\n",
    "As fuel costs increased for the three engine jets many of them were converted to freighters. The plane can take off weighing in at a maximum 633,000 pounds and \n",
    "carrying more than 38,000 gallons of fuel, according to Boeing, which bought McDonnell Douglass.\n",
    "\"\"\"\n",
    "\n",
    "# prompt construction\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Clearly summarize the following text in one concise paragraph:\n",
    "\n",
    "{text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "input = generator_tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "\n",
    "# Generate text\n",
    "with torch.no_grad():\n",
    "    outputs = generator_model.generate(\n",
    "        **input,\n",
    "        max_new_tokens=700,         # Number of tokens to generate\n",
    "        do_sample=True,             # Enable sampling for more natural output\n",
    "        temperature=0.07,            # Controls randomness\n",
    "        top_p=0.9,                  # Nucleus sampling\n",
    "        pad_token_id=generator_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# 1. Decode the raw text\n",
    "# We only want the generated part, not the input prompt\n",
    "output_token_ids = outputs[0][len(input['input_ids'][0]):]\n",
    "raw_output = generator_tokenizer.decode(output_token_ids, skip_special_tokens=True)\n",
    "\n",
    "# 2. Clean the output (it might have extra spaces)\n",
    "response_only = raw_output.strip()\n",
    "\n",
    "# 3. Wrap and print the final, correct summary\n",
    "formatted_text = textwrap.fill(response_only, width=80)\n",
    "print(\"\\n--- GENERATED SUMMARY ---\")\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71faa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating summary with Llama-3.1-Instruct...\n",
      "\n",
      "--- GENERATED SUMMARY ---\n",
      "The capital of the United States is Washington, D.C. (short for District of\n",
      "Columbia).\n"
     ]
    }
   ],
   "source": [
    "# The question you want to ask\n",
    "question = \"What is the capital of United States?\"\n",
    "\n",
    "# Build the prompt using the Llama 3.1 template\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Tokenize the prompt for the GENERATOR\n",
    "# We must set pad_token_id to eos_token_id for Llama 3\n",
    "if generator_tokenizer.pad_token_id is None:\n",
    "    generator_tokenizer.pad_token_id = generator_tokenizer.eos_token_id\n",
    "\n",
    "input = generator_tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "# Generate text using the GENERATOR model\n",
    "print(\"\\nGenerating summary with Llama-3.1-Instruct...\")\n",
    "with torch.no_grad():\n",
    "    # We must also pass the eos_token_id to stop generation\n",
    "    outputs = generator_model.generate(\n",
    "        **input,\n",
    "        max_new_tokens=750,        \n",
    "        do_sample=True,\n",
    "        temperature=0.7,         # A good temperature for creative summary\n",
    "        top_p=0.9,\n",
    "        # Llama 3.1 uses <|eot_id|> as its end token\n",
    "        eos_token_id=generator_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# 1. Decode the raw text\n",
    "# We only want the generated part, not the input prompt\n",
    "output_token_ids = outputs[0][len(input['input_ids'][0]):]\n",
    "raw_output = generator_tokenizer.decode(output_token_ids, skip_special_tokens=True)\n",
    "\n",
    "# 2. Clean the output (it might have extra spaces)\n",
    "response_only = raw_output.strip()\n",
    "\n",
    "# 3. Wrap and print the final, correct summary\n",
    "formatted_text = textwrap.fill(response_only, width=80)\n",
    "print(\"\\n--- GENERATED SUMMARY ---\")\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d1eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PDF Path ---\n",
    "PDF_FILE_PATH = \"/Users/sir/Downloads/Data/PDF/test/A_Critical_Survey_of_Bias_in_NLP.pdf\" \n",
    "\n",
    "# --- 1. PDF EXTRACTION FUNCTION ---\n",
    "def get_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a local PDF file, starting after the Abstract/Metadata, \n",
    "    stopping before \"References\", and cleaning up citation noise and URLs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening PDF '{pdf_path}': {e}\", file=sys.stderr)\n",
    "        return None\n",
    "        \n",
    "    print(f\"Reading full text from '{pdf_path}'...\")\n",
    "    text = \"\".join(page.get_text() for page in doc)\n",
    "    doc.close()\n",
    "    \n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # --- FIND THE START (Skip Abstract wording) ---\n",
    "    start_pos = 0\n",
    "    abstract_pattern = r'\\babstract\\b'\n",
    "    abstract_match = re.search(abstract_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    if abstract_match:\n",
    "        start_pos = abstract_match.end()\n",
    "    else:\n",
    "        print(\"Warning: 'Abstract' marker not found. Starting extraction from beginning.\")\n",
    "        \n",
    "    core_text = text[start_pos:]\n",
    "    \n",
    "    # --- FIND THE END (Stop before \"References\") ---\n",
    "    end_pos = len(core_text)\n",
    "    references_pattern = r'\\breferences\\b'\n",
    "    end_match = re.search(references_pattern, core_text, re.IGNORECASE)\n",
    "\n",
    "    if end_match:\n",
    "        end_pos = end_match.start()\n",
    "        print(f\"Extraction stop found immediately before: '{end_match.group(0)}'\")\n",
    "    else:\n",
    "        print(\"Warning: 'References' section not found. Extracting until EOF.\")\n",
    "\n",
    "    final_text = core_text[:end_pos]\n",
    "    \n",
    "    \n",
    "    # --- CLEANUP (Remove Citations, Links, and Fix Hyphenation) ---\n",
    "    # 1. Patterns for Citation and Link Removal (Your existing good patterns)\n",
    "    pattern_et_al = r'\\s*\\([^()]*et al\\.[^()]*\\)' \n",
    "    pattern_raw_url = r'https?:\\/\\/[^\\s\\)]+'\n",
    "    pattern_markdown_link = r'\\[https?:[^\\]]*\\]\\([^\\)]*\\)' \n",
    "    combined_pattern_noise = f'({pattern_et_al})|({pattern_raw_url})|({pattern_markdown_link})'\n",
    "\n",
    "    cleaned_text = re.sub(combined_pattern_noise, '', final_text)\n",
    "\n",
    "    # 2. Target Hyphenation Artifacts (e.g., 'popu-larity' -> 'popularity')\n",
    "    # Finds a letter, followed by a hyphen, followed optionally by spaces, followed by a letter.\n",
    "    # Replaces it with the two letters joined (e.g., a-b becomes ab).\n",
    "    pattern_broken_word = r'([a-zA-Z])-\\s*([a-zA-Z])'\n",
    "    cleaned_text = re.sub(pattern_broken_word, r'\\1\\2', cleaned_text)\n",
    "\n",
    "    # 3. Final Whitespace Cleanup\n",
    "    # This removes excess newlines/spaces (and any remaining hyphenation artifacts that had a space)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    print(f\"Successfully extracted and cleaned {len(cleaned_text)} characters.\")\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7370f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading full text from '/Users/sir/Downloads/Data/PDF/test/DataAugmentationApproachesforNLP.pdf'...\n",
      "Extraction stop found immediately before: 'References'\n",
      "Successfully extracted and cleaned 36325 characters.\n",
      "Document Title: \n",
      "Document Author: \n",
      "PDF File Path: /Users/sir/Downloads/Data/PDF/test/DataAugmentationApproachesforNLP.pdf\n",
      "\n",
      " A Survey of Data Augmentation Approaches for NLP\n",
      "Steven Y. Feng∗, 1 Varun Gangal∗, 1 Jason Wei†, 2 Sarath Chandar,3\n",
      "Soroush Vosoughi,4 Teruko Mitamura,1 Eduard Hovy1\n",
      "1Carnegie Mellon University, 2Google Research\n",
      "3Mila - Quebec AI Institute, 4Dartmouth College\n",
      "{syfeng,vgangal,teruko,hovy}@cs.cmu.edu\n",
      "jasonwei@google.com\n",
      "sarath.chandar@mila.quebec\n",
      "soroush@dartmouth.edu\n",
      "Abstract\n",
      "Data augmentation has recently seen increased\n",
      "interest in NLP due to more work in low-\n",
      "resource domains, new tasks, and the popu-\n",
      "larity of large-scale neural networks that re-\n",
      "quire large amounts of training data.\n",
      "De-\n",
      "spite this recent upsurge, this area is still rel-\n",
      "atively underexplored, perhaps due to the chal-\n",
      "lenges posed by the discrete nature of language\n",
      "data. In this paper, we present a comprehen-\n",
      "sive and unifying survey of data augmenta-\n",
      "tion for NLP by summarizing the literature in\n",
      "a structured manner. We ﬁrst introduce and\n",
      "motivate data augmentation for NLP, and then\n",
      "discuss major methodologically representative\n",
      "approaches.\n",
      "Next, we highlight techniques\n",
      "that are used for popular NLP applications and\n",
      "tasks. We conclude by outlining current chal-\n",
      "lenges and directions for future research. Over-\n",
      "all, our paper aims to clarify the landscape\n",
      "of existing literature in data augmentation for\n",
      "NLP and motivate additional work in this area.\n",
      "We also present a GitHub repository with a pa-\n",
      "per list that will be continuously updated at\n",
      "https://github.com/styfeng/DataAug4NLP.\n",
      "1\n",
      "Introduction\n",
      "Data augmentation (DA) refers to strategies for in-\n",
      "creasing the diversity of training examples without\n",
      "explicitly collecting new data. It has received active\n",
      "attention in recent machine learning (ML) research\n",
      "in the form of well-received, general-purpose tech-\n",
      "niques such as UDA (Xie et al., 2020) (3.1), which\n",
      "used backtranslation (Sennrich et al., 2016), Au-\n",
      "toAugment (Cubuk et al., 2018), and RandAugment\n",
      "(Cubuk et al., 2020), and MIXUP (Zhang et al.,\n",
      "2017) (3.2). These are often ﬁrst explored in com-\n",
      "puter vision (CV), and DA’s adaptation for natural\n",
      "language processing (NLP) seems secondary and\n",
      "∗Equal contribution by the two authors.\n",
      "† AI Resident.\n",
      "comparatively underexplored, perhaps due to chal-\n",
      "lenges presented by the discrete nature of language,\n",
      "which rules out continuous noising and makes it\n",
      "more difﬁcult to maintain invariance.\n",
      "Despite these challenges, there has been in-\n",
      "creased interest and demand for DA for NLP. As\n",
      "NLP grows due to off-the-shelf availability of large\n",
      "pretrained models, there are increasingly more\n",
      "tasks and domains to explore. Many of these are\n",
      "low-resource, and have a paucity of training exam-\n",
      "ples, creating many use-cases for which DA can\n",
      "play an important role. Particularly, for many non-\n",
      "classiﬁcation NLP tasks such as span-based tasks\n",
      "and generation, DA research is relatively sparse\n",
      "despite their ubiquity in real-world settings.\n",
      "Our paper aims to sensitize the NLP community\n",
      "towards this growing area of work, which has also\n",
      "seen increasing interest in ML overall (as seen in\n",
      "Figure 1). As interest and work on this topic con-\n",
      "tinue to increase, this is an opportune time for a\n",
      "paper of our kind to (i) give a bird’s eye view of\n",
      "DA for NLP, and (ii) identify key challenges to\n",
      "effectively motivate and orient interest in this area.\n",
      "To the best of our knowledge, this is the ﬁrst survey\n",
      "to take a detailed look at DA methods for NLP.1\n",
      "This paper is structured as follows.\n",
      "Section\n",
      "2 discusses what DA is, its goals and trade-offs,\n",
      "and why it works. Section 3 describes popular\n",
      "methodologically representative DA techniques for\n",
      "NLP—which we categorize into rule-based (3.1),\n",
      "example interpolation-based (3.2), or model-based\n",
      "(3.3). Section 4 discusses useful NLP applications\n",
      "for DA, including low-resource languages (4.1),\n",
      "mitigating bias (4.2), ﬁxing class imbalance (4.3),\n",
      "few-shot learning (4.4), and adversarial examples\n",
      "(4.5). Section 5 describes DA methods for common\n",
      "1Liu et al. (2020a) present a smaller-scale text data aug-\n",
      "mentation survey that is concise and focused. Our work serves\n",
      "as a more comprehensive survey with larger coverage and is\n",
      "more up-to-date.\n",
      "arXiv:2105.03075v5  [cs.CL]  1 Dec 2021\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'format': 'PDF 1.5',\n",
       " 'title': '',\n",
       " 'author': '',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'producer': 'pdfTeX-1.40.21',\n",
       " 'creationDate': 'D:20211203020921Z',\n",
       " 'modDate': 'D:20211203020921Z',\n",
       " 'trapped': '',\n",
       " 'encryption': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF_FILE_PATH = \"/Users/sir/Downloads/Data/PDF/test/DataAugmentationApproachesforNLP.pdf\" \n",
    "text = get_text_from_pdf(PDF_FILE_PATH)\n",
    "\n",
    "# Open the PDF document\n",
    "doc = fitz.open(PDF_FILE_PATH)\n",
    "\n",
    "## Accessing Title and Author\n",
    "\n",
    "# 1. Get the document's metadata dictionary\n",
    "metadata = doc.metadata\n",
    "\n",
    "# 2. Extract the 'title' and 'author' keys\n",
    "title = metadata.get('title', 'N/A')\n",
    "author = metadata.get('author', 'N/A')\n",
    "\n",
    "# 3. Print the results\n",
    "print(f\"Document Title: {title}\")\n",
    "print(f\"Document Author: {author}\")\n",
    "\n",
    "print(f\"PDF File Path: {PDF_FILE_PATH}\")\n",
    "\n",
    "# Access text or other content from a page (0-based index)\n",
    "page = doc.load_page(0)\n",
    "text = page.get_text()\n",
    "print(\"\\n\",text)\n",
    "\n",
    "# Don't forget to close the document\n",
    "doc.close()\n",
    "\n",
    "doc.metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af253e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Survey of Data Augmentation Approaches for NLP Steven Y. Feng∗, 1 Varun Gangal∗, 1 Jason Wei†, 2 Sarath Chandar,3\n",
      "Soroush Vosoughi,4 Teruko Mitamura,1 Eduard Hovy1 1Carnegie Mellon University, 2Google Research 3Mila - Quebec AI\n",
      "Institute, 4Dartmouth College {syfeng,vgangal,teruko,hovy}@cs.cmu.edu jasonwei@google.com sarath.chandar@mila.quebec\n",
      "soroush@dartmouth.edu Abstract Data augmentation has recently seen increased interest in NLP due to more work in low-\n",
      "resource domains, new tasks, and the popu- larity of large-scale neural networks that re- quire large amounts of\n",
      "training data. De- spite this recent upsurge, this area is still rel- atively underexplored, perhaps due to the chal-\n",
      "lenges posed by the discrete nature of language data. In this paper, we present a comprehen- sive and unifying survey of\n",
      "data augmenta- tion for NLP by summarizing the literature in a structured manner. We ﬁrst introduce and motivate data\n",
      "augmentation for NLP, and then discuss major methodologically representative approaches. Next, we highlight techniques\n",
      "that are used for popular NLP applications and tasks. We conclude by outlining current chal- lenges and directions for\n",
      "future research. Over- all, our paper aims to clarify the landscape of existing literature in data augmentation for NLP\n",
      "and motivate additional work in this area. We also present a GitHub repository with a pa- per list that will be\n",
      "continuously updated at https://github.com/styfeng/DataAug4NLP. 1 Introduction Data augmentation (DA) refers to\n",
      "strategies for in- creasing the diversity of training examples without explicitly collecting new data. It has received\n",
      "active attention in recent machine learning (ML) research in the form of well-received, general-purpose tech- niques\n",
      "such as UDA (Xie et al., 2020) (3.1), which used backtranslation (Sennrich et al., 2016), Au- toAugment (Cubuk et al.,\n",
      "2018), and RandAugment (Cubuk et al., 2020), and MIXUP (Zhang et al., 2017) (3.2). These are often ﬁrst explored in com-\n",
      "puter vision (CV), and DA’s adaptation for natural language processing (NLP) seems secondary and ∗Equal contribution by\n",
      "the two authors. † AI Resident. comparatively underexplored, perhaps due to chal- lenges presented by the discrete\n",
      "nature of language, which rules out continuous noising and makes it more difﬁcult to maintain invariance. Despite these\n",
      "challenges, there has been in- creased interest and demand for DA for NLP. As NLP grows due to off-the-shelf\n",
      "availability of large pretrained models, there are increasingly more tasks and domains to explore. Many of these are\n",
      "low-resource, and have a paucity of training exam- ples, creating many use-cases for which DA can play an important\n",
      "role. Particularly, for many non- classiﬁcation NLP tasks such as span-based tasks and generation, DA research is\n",
      "relatively sparse despite their ubiquity in real-world settings. Our paper aims to sensitize the NLP community towards\n",
      "this growing area of work, which has also seen increasing interest in ML overall (as seen in Figure 1). As interest and\n",
      "work on this topic con- tinue to increase, this is an opportune time for a paper of our kind to (i) give a bird’s eye\n",
      "view of DA for NLP, and (ii) identify key challenges to effectively motivate and orient interest in this area. To the\n",
      "best of our knowledge, this is the ﬁrst survey to take a detailed look at DA methods for NLP.1 This paper is structured\n",
      "as follows. Section 2 discusses what DA is, its goals and trade-offs, and why it works. Section 3 describes popular\n",
      "methodologically representative DA techniques for NLP—which we categorize into rule-based (3.1), example interpolation-\n",
      "based (3.2), or model-based (3.3). Section 4 discusses useful NLP applications for DA, including low-resource languages\n",
      "(4.1), mitigating bias (4.2), ﬁxing class imbalance (4.3), few-shot learning (4.4), and adversarial examples (4.5).\n",
      "Section 5 describes DA methods for common 1Liu et al. (2020a) present a smaller-scale text data aug- mentation survey\n",
      "that is concise and focused. Our work serves as a more comprehensive survey with larger coverage and is more up-to-date.\n",
      "arXiv:2105.03075v5  [cs.CL]  1 Dec 2021\n"
     ]
    }
   ],
   "source": [
    "text = textwrap.fill(text, width=120)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2986be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Generator: /Users/sir/Downloads/HuggingFace/LLM/meta-Llama-3.2-1B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# --- MODEL 1: THE \"GENERATOR\" (Llama 3.1 for summarizing) ---\n",
    "print(f\"Loading Generator: {LLM_PATH}\")\n",
    "\n",
    "# This line will now work correctly\n",
    "generator_model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLM_PATH, \n",
    "    device_map=DEVICE, # Automatically map to your M3 GPU\n",
    "    dtype=torch.float32, # Use float32 for M3\n",
    "    trust_remote_code=True\n",
    ")\n",
    "generator_tokenizer = AutoTokenizer.from_pretrained(LLM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "166eaad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating summary with Llama-3.1-Instruct...\n",
      "\n",
      "--- GENERATED SUMMARY ---\n",
      "Here's a summary of the text:  The paper discusses the concept of data\n",
      "augmentation (DA) in Natural Language Processing (NLP), which refers to\n",
      "techniques used to increase the diversity of training data without collecting\n",
      "new data. Despite its growing interest, DA is still underexplored in the NLP\n",
      "community, particularly in low-resource domains and tasks where large amounts of\n",
      "training data are scarce.  The authors review the literature on DA, categorizing\n",
      "it into three approaches: rule-based, example interpolation-based, and model-\n",
      "based. They also discuss popular NLP applications and tasks that benefit from\n",
      "DA, including:  * Low-resource languages * Mitigating bias * Fxing class\n",
      "imbalance * Few-shot learning * Adversarial examples  The authors also highlight\n",
      "the challenges associated with DA, including the discrete nature of language\n",
      "data and the need to maintain invariance during training.  The paper aims to\n",
      "clarify the current state of the field and motivate further research in DA for\n",
      "NLP. It concludes that DA is a promising area of research with increasing\n",
      "interest in the ML community, but that there is still a need for more\n",
      "comprehensive and up-to-date coverage.  Key takeaways:  * Data augmentation is a\n",
      "crucial technique in NLP that has seen increased interest in recent years * DA\n",
      "is a well-established technique in computer vision, but its adaptation for NLP\n",
      "is underexplored * Popular NLP applications and tasks that benefit from DA\n",
      "include low-resource languages, mitigating bias, and few-shot learning * The\n",
      "challenges associated with DA include the discrete nature of language data and\n",
      "the need to maintain invariance during training.\n"
     ]
    }
   ],
   "source": [
    "# prompt construction\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Summarize the following text:\n",
    "\n",
    "{text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "input = generator_tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "# --- Tokenizer Configuration ---\n",
    "# Ensure pad_token_id is set before tokenizing or generating\n",
    "if generator_tokenizer.pad_token_id is None:\n",
    "    generator_tokenizer.pad_token_id = generator_tokenizer.eos_token_id\n",
    "\n",
    "# Define the terminators for Llama 3.1\n",
    "terminators = [\n",
    "    generator_tokenizer.eos_token_id,\n",
    "    generator_tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "# --- Generate text ---\n",
    "print(\"\\nGenerating summary with Llama-3.1-Instruct...\")\n",
    "with torch.no_grad():\n",
    "    outputs = generator_model.generate(\n",
    "        **input,\n",
    "        max_new_tokens=750,        \n",
    "        do_sample=True,\n",
    "        # Increase temperature slightly for stability on bfloat16/MPS\n",
    "        temperature=0.7,             # Standard, moderate randomness\n",
    "        top_p=0.9,                  \n",
    "        # Use the list of terminators for Llama 3.1\n",
    "        eos_token_id=terminators,    # Use the list of terminators\n",
    "        pad_token_id=generator_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# 1. Decode the raw text\n",
    "output_token_ids = outputs[0][len(input['input_ids'][0]):]\n",
    "raw_output = generator_tokenizer.decode(output_token_ids, skip_special_tokens=True)\n",
    "\n",
    "# 2. Clean the output\n",
    "response_only = raw_output.strip()\n",
    "\n",
    "# 3. Wrap and print the final, correct summary\n",
    "formatted_text = textwrap.fill(response_only, width=80)\n",
    "print(\"\\n--- GENERATED SUMMARY ---\")\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac56a0f4",
   "metadata": {},
   "source": [
    "## New PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdcc0e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading full text from '/Users/sir/Downloads/Data/PDF/test/A_Critical_Survey_of_Bias_in_NLP.pdf'...\n",
      "Extraction stop found immediately before: 'References'\n",
      "Successfully extracted and cleaned 39150 characters.\n"
     ]
    }
   ],
   "source": [
    "PDF_FILE_PATH = \"/Users/sir/Downloads/Data/PDF/test/A_Critical_Survey_of_Bias_in_NLP.pdf\" \n",
    "text = get_text_from_pdf(PDF_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8459c6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We survey 146 papers analyzing “bias” in NLP systems, ﬁnding that their motivations are often vague, inconsistent, and\n",
      "lacking in normative reasoning, despite the fact that analyzing “bias” is an inherently normative process. We further\n",
      "ﬁnd that these papers’ proposed quantitative techniques for measuring or mitigating “bias” are poorly matched to their\n",
      "motivations and do not engage with the relevant literature outside of NLP. Based on these ﬁndings, we describe the\n",
      "beginnings of a path forward by proposing three recommendations that should guide work analyzing “bias” in NLP systems.\n",
      "These recommendations rest on a greater recognition of the relationships between language and social hierarchies,\n",
      "encouraging researchers and practitioners to articulate their conceptualizations of “bias”—i.e., what kinds of system\n",
      "behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these\n",
      "statements—and to center work around the lived experiences of members of communities affected by NLP systems, while\n",
      "interrogating and reimagining the power relations between technologists and such communities. 1 Introduction A large\n",
      "body of work analyzing “bias” in natural language processing (NLP) systems has emerged in recent years, including work\n",
      "on “bias” in embedding spaces as well as work on “bias” in systems developed for a breadth of tasks including language\n",
      "modeling, coreference resolution, machine translation, sentiment analysis (Kiritchenko and Mohammad, 2018), and hate\n",
      "speech/toxicity detection, among others. Although these papers have laid vital groundwork by illustrating some of the\n",
      "ways that NLP systems can be harmful, the majority of them fail to engage critically with what constitutes “bias” in the\n",
      "ﬁrst place. Despite the fact that analyzing “bias” is an inherently normative process—in which some system behaviors are\n",
      "deemed good and others harmful—papers on “bias” in NLP systems are rife with unstated assumptions about what kinds of\n",
      "system behaviors are harmful, in what ways, to whom, and why. Indeed, the term “bias” (or “gender bias” or “racial\n",
      "bias”) is used to describe a wide range of system behaviors, even though they may be harmful in different ways, to\n",
      "different groups, or for different reasons. Even papers analyzing “bias” in NLP systems developed for the same task\n",
      "often conceptualize it differently. For example, the following system behaviors are all understood to be selfevident\n",
      "statements of “racial bias”: (a) embedding spaces in which embeddings for names associated with African Americans are\n",
      "closer (compared to names associated with European Americans) to unpleasant words than pleasant words; (b) sentiment\n",
      "analysis systems yielding different intensity scores for sentences containing names associated with African Americans\n",
      "and sentences containing names associated with European Americans (Kiritchenko and Mohammad, 2018); and (c) toxicity\n",
      "arXiv:2005.14050v2 [cs.CL] 29 May 2020 detection systems scoring tweets containing features associated with\n",
      "AfricanAmerican English as more offensive than tweets without these features. Moreover, some of these papers focus on\n",
      "“racial bias” expressed in written text, while others focus on “racial bias” against authors. This use of imprecise\n",
      "terminology obscures these important differences. We survey 146 papers analyzing “bias” in NLP systems, ﬁnding that\n",
      "their motivations are often vague and inconsistent. Many lack any normative reasoning for why the system behaviors that\n",
      "are described as “bias” are harmful, in what ways, and to whom. Moreover, the vast majority of these papers do not\n",
      "engage with the relevant literature outside of NLP to ground normative concerns when proposing quantitative techniques\n",
      "for measuring or mitigating “bias.” As a result, we ﬁnd that many of these techniques are poorly matched to their\n",
      "motivations, and are not comparable to one another. We then describe the beginnings of a path forward by proposing three\n",
      "recommendations that should guide work analyzing “bias” in NLP systems. We argue that such work should examine the\n",
      "relationships between language and social hierarchies; we call on researchers and practitioners conducting such work to\n",
      "articulate their conceptualizations of “bias” in order to enable conversations about what kinds of system behaviors are\n",
      "harmful, in what ways, to whom, and why; and we recommend deeper engagements between technologists and communities\n",
      "affected by NLP systems. We also provide several concrete research questions that are implied by each of our\n",
      "recommendations. 2 Method Our survey includes all papers known to us analyzing “bias” in NLP systems—146 papers in\n",
      "total. We omitted papers about speech, restricting our survey to papers about written text only. To identify the 146\n",
      "papers, we ﬁrst searched the ACL Anthology1 for all papers with the keywords “bias” or “fairness” that were made\n",
      "available prior to May 2020. We retained all papers about social “bias,” and discarded all papers about other deﬁnitions\n",
      "of the keywords (e.g., hypothesisonly bias, inductive bias, media bias). We also discarded all papers using “bias” in\n",
      "NLP systems to measure social “bias” in text or the real world. To ensure that we did not exclude any relevant 1 NLP\n",
      "task Papers Embeddings (typelevel or contextualized) 54 Coreference resolution 20 Language modeling or dialogue\n",
      "generation 17 Hatespeech detection 17 Sentiment analysis 15 Machine translation 8 Tagging or parsing 5 Surveys,\n",
      "frameworks, and metaanalyses 20 Other 22 Table 1: The NLP tasks covered by the 146 papers. papers without the keywords\n",
      "“bias” or “fairness,” we also traversed the citation graph of our initial set of papers, retaining any papers analyzing\n",
      "“bias” in NLP systems that are cited by or cite the papers in our initial set. Finally, we manually inspected any papers\n",
      "analyzing “bias” in NLP systems from leading machine learning, human–computer interaction, and web conferences and\n",
      "workshops, such as ICML, NeurIPS, AIES, FAccT, CHI, and WWW, along with any relevant papers that were made available in\n",
      "the “Computation and Language” and “Computers and Society” categories on arXiv prior to May 2020, but found that they\n",
      "had already been identiﬁed via our traversal of the citation graph. We provide a list of all 146 papers in the appendix.\n",
      "In Table 1, we provide a breakdown of the NLP tasks covered by the papers. We note that counts do not sum to 146,\n",
      "because some papers cover multiple tasks. For example, a paper might test the efﬁcacy of a technique for mitigating\n",
      "“bias” in embedding spaces in the context of sentiment analysis. Once identiﬁed, we then read each of the 146 papers\n",
      "with the goal of categorizing their motivations and their proposed quantitative techniques for measuring or mitigating\n",
      "“bias.” We used a previously developed taxonomy of harms for this categorization, which differentiates between socalled\n",
      "allocational and representational harms. Allocational harms arise when an automated system allocates resources (e.g.,\n",
      "credit) or opportunities (e.g., jobs) unfairly to different social groups; representational harms arise when a system\n",
      "(e.g., a search engine) represents some social groups in a less favorable light than others, demeans them, or fails to\n",
      "recognize their existence altogether. Adapting and extending this taxonomy, we categorized the 146 papers’ motivations\n",
      "and techniques into the following categories: ▷Allocational harms. Papers Category Motivation Technique Allocational\n",
      "harms 30 4 Stereotyping 50 58 Other representational harms 52 43 Questionable correlations 47 42 Vague/unstated 23 0\n",
      "Surveys, frameworks, and metaanalyses 20 20 Table 2: The categories into which the 146 papers fall. ▷Representational\n",
      "harms:2 ▷Stereotyping that propagates negative generalizations about particular social groups. ▷Differences in system\n",
      "performance for different social groups, language that misrepresents the distribution of different social groups in the\n",
      "population, or language that is denigrating to particular social groups. ▷Questionable correlations between system\n",
      "behavior and features of language that are typically associated with particular social groups. ▷Vague descriptions of\n",
      "“bias” (or “gender bias” or “racial bias”) or no description at all. ▷Surveys, frameworks, and metaanalyses. In Table 2\n",
      "we provide counts for each of the six categories listed above. (We also provide a list of the papers that fall into each\n",
      "category in the appendix.) Again, we note that the counts do not sum to 146, because some papers state multiple\n",
      "motivations, propose multiple techniques, or propose a single technique for measuring or mitigating multiple harms.\n",
      "Table 3, which is in the appendix, contains examples of the papers’ motivations and techniques across a range of\n",
      "different NLP tasks. 3 Findings Categorizing the 146 papers’ motivations and proposed quantitative techniques for\n",
      "measuring or mitigating “bias” into the six categories listed above enabled us to identify several commonalities, which\n",
      "we present below, along with illustrative quotes. 2We grouped several types of representational harms into two\n",
      "categories to reﬂect that the main point of differentiation between the 146 papers’ motivations and proposed\n",
      "quantitative techniques for measuring or mitigating “bias” is whether or not they focus on stereotyping. Among the\n",
      "papers that do not focus on stereotyping, we found that most lack sufﬁciently clear motivations and techniques to\n",
      "reliably categorize them further. 3.1 Motivations Papers state a wide range of motivations, multiple motivations, vague\n",
      "motivations, and sometimes no motivations at all. We found that the papers’ motivations span all six categories, with\n",
      "several papers falling into each one. Appropriately, papers that provide surveys or frameworks for analyzing “bias” in\n",
      "NLP systems often state multiple motivations. However, as the examples in Table 3 (in the appendix) illustrate, many\n",
      "other papers (33%) do so as well. Some papers (16%) state only vague motivations or no motivations at all. For example,\n",
      "“[N]o human should be discriminated on the basis of demographic attributes by an NLP system.” —Kaneko and Bollegala\n",
      "(2019) “[P]rominent word embeddings [...] encode systematic biases against women and black people [...] implicating many\n",
      "NLP systems in scaling up social injustice.” —May et al. (2019) These examples leave unstated what it might mean for an\n",
      "NLP system to “discriminate,” what constitutes “systematic biases,” or how NLP systems contribute to “social injustice”\n",
      "(itself undeﬁned). Papers’ motivations sometimes include no normative reasoning. We found that some papers (32%) are not\n",
      "motivated by any apparent normative concerns, often focusing instead on concerns about system performance. For example,\n",
      "the ﬁrst quote below includes normative reasoning—namely that models should not use demographic information to make\n",
      "predictions—while the other focuses on learned correlations impairing system performance. “In [text classiﬁcation],\n",
      "models are expected to make predictions with the semantic information rather than with the demographic group identity\n",
      "information (e.g., ‘gay’, ‘black’) contained in the sentences.” —Zhang et al. (2020a) “An overprevalence of some\n",
      "gendered forms in the training data leads to translations with identiﬁable errors. Translations are better for sentences\n",
      "involving men and for sentences containing stereotypical gender roles.” —Saunders and Byrne (2020) Even when papers do\n",
      "state clear motivations, they are often unclear about why the system behaviors that are described as “bias” are harmful,\n",
      "in what ways, and to whom. We found that even papers with clear motivations often fail to explain what kinds of system\n",
      "behaviors are harmful, in what ways, to whom, and why. For example, “Deploying these word embedding algorithms in\n",
      "practice, for example in automated translation systems or as hiring aids, runs the serious risk of perpetuating\n",
      "problematic biases in important societal contexts.” —Brunet et al. (2019) “[I]f the systems show discriminatory\n",
      "behaviors in the interactions, the user experience will be adversely affected.” —Liu et al. (2019) These examples leave\n",
      "unstated what “problematic biases” or nonideal user experiences might look like, how the system behaviors might result\n",
      "in these things, and who the relevant stakeholders or users might be. In contrast, we ﬁnd that papers that provide\n",
      "surveys or frameworks for analyzing “bias” in NLP systems often name who is harmed, acknowledging that different social\n",
      "groups may experience these systems differently due to their different relationships with NLP systems or different\n",
      "social positions. For example, Ruane et al. (2019) argue for a “deep understanding of the user groups [sic]\n",
      "characteristics, contexts, and interests” when designing conversational agents. Papers about NLP systems developed for\n",
      "the same task often conceptualize “bias” differently. Even papers that cover the same NLP task often conceptualize\n",
      "“bias” in ways that differ substantially and are sometimes inconsistent. Rows 3 and 4 of Table 3 (in the appendix)\n",
      "contain machine translation papers with different conceptualizations of “bias,” leading to different proposed\n",
      "techniques, while rows 5 and 6 contain papers on “bias” in embedding spaces that state different motivations, but\n",
      "propose techniques for quantifying stereotyping. Papers’ motivations conﬂate allocational and representational harms. We\n",
      "found that the papers’ motivations sometimes (16%) name immediate representational harms, such as stereotyping,\n",
      "alongside more distant allocational harms, which, in the case of stereotyping, are usually imagined as downstream\n",
      "effects of stereotypes on résumé ﬁltering. Many of these papers use the imagined downstream effects to justify focusing\n",
      "on particular system behaviors, even when the downstream effects are not measured. Papers on “bias” in embedding spaces\n",
      "are especially likely to do this because embeddings are often used as input to other systems: “However, none of these\n",
      "papers [on embeddings] have recognized how blatantly sexist the embeddings are and hence risk introducing biases of\n",
      "various types into realworld systems.” —Bolukbasi et al. (2016a) “It is essential to quantify and mitigate gender bias\n",
      "in these embeddings to avoid them from affecting downstream applications.” —Zhou et al. (2019) In contrast, papers that\n",
      "provide surveys or frameworks for analyzing “bias” in NLP systems treat representational harms as harmful in their own\n",
      "right. For example, Mayﬁeld et al. (2019) and Ruane et al. (2019) cite the harmful reproduction of dominant linguistic\n",
      "norms by NLP systems (a point to which we return in section 4), while Bender (2019) outlines a range of harms, including\n",
      "seeing stereotypes in search results and being made invisible to search engines due to language practices. 3.2\n",
      "Techniques Papers’ techniques are not well grounded in the relevant literature outside of NLP. Perhaps unsurprisingly\n",
      "given that the papers’ motivations are often vague, inconsistent, and lacking in normative reasoning, we also found that\n",
      "the papers’ proposed quantitative techniques for measuring or mitigating “bias” do not effectively engage with the\n",
      "relevant literature outside of NLP. Papers on stereotyping are a notable exception: the Word Embedding Association Test\n",
      "draws on the Implicit Association Test from the social psychology literature, while several techniques operationalize\n",
      "the wellstudied “Angry Black Woman” stereotype and the “double bind” faced by women, in which women who succeed at\n",
      "stereotypically male tasks are perceived to be less likable than similarly successful men. Tan and Celis (2019) also\n",
      "examine the compounding effects of race and gender, drawing on Black feminist scholarship on intersectionality\n",
      "(Crenshaw, 1989). Papers’ techniques are poorly matched to their motivations. We found that although 21% of the papers\n",
      "include allocational harms in their motivations, only four papers actually propose techniques for measuring or\n",
      "mitigating allocational harms. Papers focus on a narrow range of potential sources of “bias.” We found that nearly all\n",
      "of the papers focus on system predictions as the potential sources of “bias,” with many additionally focusing on “bias”\n",
      "in datasets (e.g., differences in the number of gendered pronouns in the training data). Most papers do not interrogate\n",
      "the normative implications of other decisions made during the development and deployment lifecycle— perhaps unsurprising\n",
      "given that their motivations sometimes include no normative reasoning. A few papers are exceptions, illustrating the\n",
      "impacts of task deﬁnitions, annotation guidelines, and evaluation metrics: Cao and Daumé (2019) study how folk\n",
      "conceptions of gender (Keyes, 2018) are reproduced in coreference resolution systems that assume a strict gender\n",
      "dichotomy, thereby maintaining cisnormativity; Sap et al. (2019) focus on the effect of priming annotators with\n",
      "information about possible dialectal differences when asking them to apply toxicity labels to sample tweets, ﬁnding that\n",
      "annotators who are primed are signiﬁcantly less likely to label tweets containing features associated with\n",
      "AfricanAmerican English as offensive. 4 A path forward We now describe how researchers and practitioners conducting work\n",
      "analyzing “bias” in NLP systems might avoid the pitfalls presented in the previous section—the beginnings of a path\n",
      "forward. We propose three recommendations that should guide such work, and, for each, provide several concrete research\n",
      "questions. We emphasize that these questions are not comprehensive, and are intended to generate further questions and\n",
      "lines of engagement. Our three recommendations are as follows: (R1) Ground work analyzing “bias” in NLP systems in the\n",
      "relevant literature outside of NLP that explores the relationships between language and social hierarchies. Treat\n",
      "representational harms as harmful in their own right. (R2) Provide explicit statements of why the system behaviors that\n",
      "are described as “bias” are harmful, in what ways, and to whom. Be forthright about the normative reasoning (Green,\n",
      "2019) underlying these statements. (R3) Examine language use in practice by engaging with the lived experiences of\n",
      "members of communities affected by NLP systems. Interrogate and reimagine the power relations between technologists and\n",
      "such communities. 4.1 Language and social hierarchies Turning ﬁrst to (R1), we argue that work analyzing “bias” in NLP\n",
      "systems will paint a much fuller picture if it engages with the relevant literature outside of NLP that explores the\n",
      "relationships between language and social hierarchies. Many disciplines, including sociolinguistics, linguistic\n",
      "anthropology, sociology, and social psychology, study how language takes on social meaning and the role that language\n",
      "plays in maintaining social hierarchies. For example, language is the means through which social groups are labeled and\n",
      "one way that beliefs about social groups are transmitted (e.g., Maass, 1999; Beukeboom and Burgers, 2019). Group labels\n",
      "can serve as the basis of stereotypes and thus reinforce social inequalities: “[T]he label content functions to identify\n",
      "a given category of people, and thereby conveys category boundaries and a position in a hierarchical taxonomy”\n",
      "(Beukeboom and Burgers, 2019). Similarly, “controlling images,” such as stereotypes of Black women, which are\n",
      "linguistically and visually transmitted through literature, news media, television, and so forth, provide “ideological\n",
      "justiﬁcation” for their continued oppression (Collins, 2000, Chapter 4). As a result, many groups have sought to bring\n",
      "about social changes through changes in language, disrupting patterns of oppression and marginalization via socalled\n",
      "“genderfair” language, language that is more inclusive to people with disabilities (ADA, 2018), and language that is\n",
      "less dehumanizing (e.g., abandoning the use of the term “illegal” in everyday discourse on immigration in the U.S.\n",
      "(Rosa, 2019)). The fact that group labels are so contested is evidence of how deeply intertwined language and social\n",
      "hierarchies are. Taking “genderfair” language as an example, the hope is that reducing asymmetries in language about\n",
      "women and men will reduce asymmetries in their social standing. Meanwhile, struggles over language use often arise from\n",
      "dominant social groups’ desire to “control both material and symbolic resources”—i.e., “the right to decide what words\n",
      "will mean and to control those meanings”—as was the case in some white speakers’ insistence on using offensive place\n",
      "names against the objections of Indigenous speakers (Hill, 2008, Chapter 3). Sociolinguists and linguistic\n",
      "anthropologists have also examined language attitudes and language ideologies, or people’s metalinguistic beliefs about\n",
      "language: Which language varieties or practices are taken as standard, ordinary, or unmarked? Which are considered\n",
      "correct, prestigious, or appropriate for public use, and which are considered incorrect, uneducated, or offensive (e.g.,\n",
      "CampbellKibler, 2009; Preston, 2009; Loudermilk, 2015; Lanehart and Malik, 2018)? Which are rendered invisible (Roche,\n",
      "2019)?3 Language ideologies play a vital role in reinforcing and justifying social hierarchies because beliefs about\n",
      "language varieties or practices often translate into beliefs about their speakers. For example, in the U.S., the\n",
      "portrayal of nonwhite speakers’ language varieties and practices as linguistically deﬁcient helped to justify violent\n",
      "European colonialism, and today continues to justify enduring racial hierarchies by maintaining views of nonwhite\n",
      "speakers as lacking the language “required for complex thinking processes and successful engagement in the global\n",
      "economy” (Rosa and Flores, 2017). Recognizing the role that language plays in maintaining social hierarchies is critical\n",
      "to the future of work analyzing “bias” in NLP systems. First, it helps to explain why representational harms are harmful\n",
      "in their own right. Second, the complexity of the relationships between language and social hierarchies illustrates why\n",
      "studying “bias” in NLP systems is so challenging, suggesting that researchers and practitioners will need to move beyond\n",
      "existing algorithmic fairness techniques. We argue that work must be grounded in the relevant literature outside of NLP\n",
      "that examines the relationships between language and social hierarchies; without this grounding, researchers and\n",
      "practitioners risk measuring or mitigating only what is convenient to measure or mitigate, rather than what is most\n",
      "normatively concerning. More speciﬁcally, we recommend that work analyzing “bias” in NLP systems be reoriented around\n",
      "the following question: How are social hierarchies, language ideologies, and NLP systems coproduced? This question\n",
      "mirrors Benjamin’s (2020) call to examine how “race and technology are coproduced”—i.e., how racial hierarchies, and the\n",
      "ideologies and discourses that maintain them, create and are recreated by technology. We recommend that researchers and\n",
      "practitioners similarly ask how existing social hierarchies and language ideologies drive the development and deployment\n",
      "of NLP systems, and how these systems therefore reproduce these hierarchies and ideologies. As a starting point for\n",
      "reorienting work analyzing “bias” in NLP systems around this question, we 3Language ideologies encompass much more than\n",
      "this; see, e.g., LippiGreen (2012), Alim et al. (2016), Rosa and Flores (2017), Rosa and Burdick (2017), and Charity\n",
      "Hudley (2017). provide the following concrete research questions: ▷How do social hierarchies and language ideologies\n",
      "inﬂuence the decisions made during the development and deployment lifecycle? What kinds of NLP systems do these\n",
      "decisions result in, and what kinds do they foreclose? ⋄General assumptions: To which linguistic norms do NLP systems\n",
      "adhere? Which language practices are implicitly assumed to be standard, ordinary, correct, or appropriate? ⋄Task\n",
      "deﬁnition: For which speakers are NLP systems (and NLP resources) developed? (See Joshi et al. (2020) for a discussion.)\n",
      "How do task deﬁnitions discretize the world? For example, how are social groups delineated when deﬁning demographic\n",
      "attribute prediction tasks? What about languages in native language prediction tasks? ⋄Data: How are datasets collected,\n",
      "preprocessed, and labeled or annotated? What are the impacts of annotation guidelines, annotator assumptions and\n",
      "perceptions, and annotation aggregation processes (Pavlick and Kwiatkowski, 2019)? ⋄Evaluation: How are NLP systems\n",
      "evaluated? What are the impacts of evaluation metrics? Are any nonquantitative evaluations performed? ▷How do NLP\n",
      "systems reproduce or transform language ideologies? Which language varieties or practices come to be deemed good or bad?\n",
      "Might “good” language simply mean language that is easily handled by existing NLP systems? For example, linguistic\n",
      "phenomena arising from many language practices (Eisenstein, 2013) are described as “noisy text” and often viewed as a\n",
      "target for “normalization.” How do the language ideologies that are reproduced by NLP systems maintain social\n",
      "hierarchies? ▷Which representational harms are being measured or mitigated? Are these the most normatively concerning\n",
      "harms, or merely those that are well handled by existing algorithmic fairness techniques? Are there other\n",
      "representational harms that might be analyzed? 4.2 Conceptualizations of “bias” Turning now to (R2), we argue that work\n",
      "analyzing “bias” in NLP systems should provide explicit statements of why the system behaviors that are described as\n",
      "“bias” are harmful, in what ways, and to whom, as well as the normative reasoning underlying these statements. In other\n",
      "words, researchers and practitioners should articulate their conceptualizations of “bias.” As we described above, papers\n",
      "often contain descriptions of system behaviors that are understood to be selfevident statements of “bias.” This use of\n",
      "imprecise terminology has led to papers all claiming to analyze “bias” in NLP systems, sometimes even in systems\n",
      "developed for the same task, but with different or even inconsistent conceptualizations of “bias,” and no explanations\n",
      "for these differences. Yet analyzing “bias” is an inherently normative process—in which some system behaviors are deemed\n",
      "good and others harmful—even if assumptions about what kinds of system behaviors are harmful, in what ways, for whom,\n",
      "and why are not stated. We therefore echo calls by Bardzell and Bardzell (2011), Keyes et al. (2019), and Green (2019)\n",
      "for researchers and practitioners to make their normative reasoning explicit by articulating the social values that\n",
      "underpin their decisions to deem some system behaviors as harmful, no matter how obvious such values appear to be. We\n",
      "further argue that this reasoning should take into account the relationships between language and social hierarchies\n",
      "that we described above. First, these relationships provide a foundation from which to approach the normative reasoning\n",
      "that we recommend making explicit. For example, some system behaviors might be harmful precisely because they maintain\n",
      "social hierarchies. Second, if work analyzing “bias” in NLP systems is reoriented to understand how social hierarchies,\n",
      "language ideologies, and NLP systems are coproduced, then this work will be incomplete if we fail to account for the\n",
      "ways that social hierarchies and language ideologies determine what we mean by “bias” in the ﬁrst place. As a starting\n",
      "point, we therefore provide the following concrete research questions: ▷What kinds of system behaviors are described as\n",
      "“bias”? What are their potential sources (e.g., general assumptions, task deﬁnition, data)? ▷In what ways are these\n",
      "system behaviors harmful, to whom are they harmful, and why? ▷What are the social values (obvious or not) that underpin\n",
      "this conceptualization of “bias?” 4.3 Language use in practice Finally, we turn to (R3). Our perspective, which rests on\n",
      "a greater recognition of the relationships between language and social hierarchies, suggests several directions for\n",
      "examining language use in practice. Here, we focus on two. First, because language is necessarily situated, and because\n",
      "different social groups have different lived experiences due to their different social positions—particularly groups at\n",
      "the intersections of multiple axes of oppression—we recommend that researchers and practitioners center work analyzing\n",
      "“bias” in NLP systems around the lived experiences of members of communities affected by these systems. Second, we\n",
      "recommend that the power relations between technologists and such communities be interrogated and reimagined.\n",
      "Researchers have pointed out that algorithmic fairness techniques, by proposing incremental technical mitigations—e.g.,\n",
      "collecting new datasets or training better models—maintain these power relations by (a) assuming that automated systems\n",
      "should continue to exist, rather than asking whether they should be built at all, and (b) keeping development and\n",
      "deployment decisions in the hands of technologists. There are many disciplines for researchers and practitioners to draw\n",
      "on when pursuing these directions. For example, in human–computer interaction, Hamidi et al. (2018) study transgender\n",
      "people’s experiences with automated gender recognition systems in order to uncover how these systems reproduce\n",
      "structures of transgender exclusion by redeﬁning what it means to perform gender “normally.” Valuesensitive design\n",
      "provides a framework for accounting for the values of different stakeholders in the design of technology, while\n",
      "participatory design seeks to involve stakeholders in the design process itself. Participatory action research in\n",
      "education (Kemmis, 2006) and in language documentation and reclamation (Junker, 2018) is also relevant. In particular,\n",
      "work on language reclamation to support decolonization and tribal sovereignty (Leonard, 2012) and work in\n",
      "sociolinguistics focusing on developing coequal research relationships with community members and supporting linguistic\n",
      "justice efforts provide examples of more emancipatory relationships with communities. Finally, several workshops and\n",
      "events have begun to explore how to empower stakeholders in the development and deployment of technology4 and how to\n",
      "help researchers and practitioners consider when not to build systems at all. As a starting point for engaging with\n",
      "communities affected by NLP systems, we therefore provide the following concrete research questions: ▷How do communities\n",
      "become aware of NLP systems? Do they resist them, and if so, how? ▷What additional costs are borne by communities for\n",
      "whom NLP systems do not work well? ▷Do NLP systems shift power toward oppressive institutions (e.g., by enabling\n",
      "predictions that communities do not want made, linguistically based unfair allocation of resources or opportunities\n",
      "(Rosa and Flores, 2017), surveillance, or censorship), or away from such institutions? ▷Who is involved in the\n",
      "development and deployment of NLP systems? How do decisionmaking processes maintain power relations between\n",
      "technologists and communities affected by NLP systems? Can these processes be changed to reimagine these relations? 5\n",
      "Case study To illustrate our recommendations, we present a case study covering work on AfricanAmerican English (AAE).5\n",
      "Work analyzing “bias” in the context of AAE has shown that partofspeech taggers, language identiﬁcation systems, and\n",
      "dependency parsers all work less well on text containing features associated with AAE than on text without these\n",
      "features, and that toxicity detection systems score tweets containing features associated with AAE as more offensive\n",
      "than tweets without them. These papers have been critical for highlighting AAE as a language variety for which existing\n",
      "NLP 4Also 5This language variety has had many different names over the years, but is now generally called\n",
      "AfricanAmerican English (AAE), AfricanAmerican Vernacular English (AAVE), or AfricanAmerican Language (AAL) (Green,\n",
      "2002; Wolfram and Schilling, 2015; Rickford and King, 2016). systems may not work, illustrating their limitations.\n",
      "However, they do not conceptualize “racial bias” in the same way. The ﬁrst four of these papers simply focus on system\n",
      "performance differences between text containing features associated with AAE and text without these features. In\n",
      "contrast, the last two papers also focus on such system performance differences, but motivate this focus with the\n",
      "following additional reasoning: If tweets containing features associated with AAE are scored as more offensive than\n",
      "tweets without these features, then this might (a) yield negative perceptions of AAE; (b) result in disproportionate\n",
      "removal of tweets containing these features, impeding participation in online platforms and reducing the space available\n",
      "online in which speakers can use AAE freely; and (c) cause AAE speakers to incur additional costs if they have to change\n",
      "their language practices to avoid negative perceptions or tweet removal. More importantly, none of these papers engage\n",
      "with the literature on AAE, racial hierarchies in the U.S., and raciolinguistic ideologies. By failing to engage with\n",
      "this literature—thereby treating AAE simply as one of many nonPenn Treebank varieties of English or perhaps as another\n",
      "challenging domain—work analyzing “bias” in NLP systems in the context of AAE fails to situate these systems in the\n",
      "world. Who are the speakers of AAE? How are they viewed? We argue that AAE as a language variety cannot be separated\n",
      "from its speakers— primarily Black people in the U.S., who experience systemic antiBlack racism—and the language\n",
      "ideologies that reinforce and justify racial hierarchies. Even after decades of sociolinguistic efforts to legitimize\n",
      "AAE, it continues to be viewed as “bad” English and its speakers continue to be viewed as linguistically inadequate—a\n",
      "view called the deﬁcit perspective. This perspective persists despite demonstrations that AAE is rulebound and\n",
      "grammatical, in addition to ample evidence of its speakers’ linguistic adroitness (e.g., Alim, 2004; Rickford and King,\n",
      "2016). This perspective belongs to a broader set of raciolinguistic ideologies (Rosa and Flores, 2017), which also\n",
      "produce allocational harms; speakers of AAE are frequently penalized for not adhering to dominant language practices,\n",
      "including in the education system, when seeking housing (Baugh, 2018), and in the judicial system, where their testimony\n",
      "is misunderstood or, worse yet, disbelieved. These raciolinguistic ideologies position racialized communities as needing\n",
      "linguistic intervention, such as language education programs, in which these and other harms can be reduced if\n",
      "communities accommodate to dominant language practices (Rosa and Flores, 2017). In the technology industry, speakers of\n",
      "AAE are often not considered consumers who matter. For example, Benjamin (2019) recounts an Apple employee who worked on\n",
      "speech recognition for Siri: “As they worked on different English dialects — Australian, Singaporean, and Indian English\n",
      "— [the employee] asked his boss: ‘What about African American English?’ To this his boss responded: ‘Well, Apple\n",
      "products are for the premium market.”’ The reality, of course, is that speakers of AAE tend not to represent the\n",
      "“premium market” precisely because of institutions and policies that help to maintain racial hierarchies by\n",
      "systematically denying them the opportunities to develop wealth that are available to white Americans (Rothstein, 2017)—\n",
      "an exclusion that is reproduced in technology by countless decisions like the one described above. Engaging with the\n",
      "literature outlined above situates the system behaviors that are described as “bias,” providing a foundation for\n",
      "normative reasoning. Researchers and practitioners should be concerned about “racial bias” in toxicity detection systems\n",
      "not only because performance differences impair system performance, but because they reproduce longstanding injustices\n",
      "of stigmatization and disenfranchisement for speakers of AAE. In restigmatizing AAE, they reproduce language ideologies\n",
      "in which AAE is viewed as ungrammatical, uneducated, and offensive. These ideologies, in turn, enable linguistic\n",
      "discrimination and justify enduring racial hierarchies (Rosa and Flores, 2017). Our perspective, which understands\n",
      "racial hierarchies and raciolinguistic ideologies as structural conditions that govern the development and deployment of\n",
      "technology, implies that techniques for measuring or mitigating “bias” in NLP systems will necessarily be incomplete\n",
      "unless they interrogate and dismantle these structural conditions, including the power relations between technologists\n",
      "and racialized communities. We emphasize that engaging with the literature on AAE, racial hierarchies in the U.S., and\n",
      "raciolinguistic ideologies can generate new lines of engagement. These lines include work on the ways that the decisions\n",
      "made during the development and deployment of NLP systems produce stigmatization and disenfranchisement, and work on AAE\n",
      "use in practice, such as the ways that speakers of AAE interact with NLP systems that were not designed for them. This\n",
      "literature can also help researchers and practitioners address the allocational harms that may be produced by NLP\n",
      "systems, and ensure that even wellintentioned NLP systems do not position racialized communities as needing linguistic\n",
      "intervention or accommodation to dominant language practices. Finally, researchers and practitioners wishing to design\n",
      "better systems can also draw on a growing body of work on antiracist language pedagogy that challenges the deﬁcit\n",
      "perspective of AAE and other racialized language practices (e.g. Flores and Chaparro, 2018; BakerBell, 2019; Martínez\n",
      "and Mejía, 2019), as well as the work that we described in section 4.3 on reimagining the power relations between\n",
      "technologists and communities affected by technology. 6 Conclusion By surveying 146 papers analyzing “bias” in NLP\n",
      "systems, we found that (a) their motivations are often vague, inconsistent, and lacking in normative reasoning; and (b)\n",
      "their proposed quantitative techniques for measuring or mitigating “bias” are poorly matched to their motivations and do\n",
      "not engage with the relevant literature outside of NLP. To help researchers and practitioners avoid these pitfalls, we\n",
      "proposed three recommendations that should guide work analyzing “bias” in NLP systems, and, for each, provided several\n",
      "concrete research questions. These recommendations rest on a greater recognition of the relationships between language\n",
      "and social hierarchies—a step that we see as paramount to establishing a path forward. Acknowledgments This paper is\n",
      "based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. 1451512. Any\n",
      "opinion, ﬁndings, and conclusions or recommendations expressed in this material are those of the authors and do not\n",
      "necessarily reﬂect the views of the National Science Foundation. We thank the reviewers for their useful feedback,\n",
      "especially the suggestion to include additional details about our method.\n"
     ]
    }
   ],
   "source": [
    "text = textwrap.fill(text, width=120)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33002281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Title: Language (Technology) is Power: A Critical Survey of “Bias” in NLP\n",
      "Document Author: Su Lin Blodgett, Solon Baracas, Hal Daumé III, Hanna Wallach\n",
      "PDF File Path: /Users/sir/Downloads/Data/PDF/test/A_Critical_Survey_of_Bias_in_NLP.pdf\n",
      "\n",
      " Language (Technology) is Power: A Critical Survey of “Bias” in NLP\n",
      "Su Lin Blodgett\n",
      "College of Information and Computer Sciences\n",
      "University of Massachusetts Amherst\n",
      "blodgett@cs.umass.edu\n",
      "Solon Barocas\n",
      "Microsoft Research\n",
      "Cornell University\n",
      "solon@microsoft.com\n",
      "Hal Daumé III\n",
      "Microsoft Research\n",
      "University of Maryland\n",
      "me@hal3.name\n",
      "Hanna Wallach\n",
      "Microsoft Research\n",
      "wallach@microsoft.com\n",
      "Abstract\n",
      "We survey 146 papers analyzing “bias” in\n",
      "NLP systems, ﬁnding that their motivations\n",
      "are often vague, inconsistent, and lacking\n",
      "in normative reasoning, despite the fact that\n",
      "analyzing “bias” is an inherently normative\n",
      "process.\n",
      "We further ﬁnd that these papers’\n",
      "proposed quantitative techniques for measur-\n",
      "ing or mitigating “bias” are poorly matched to\n",
      "their motivations and do not engage with the\n",
      "relevant literature outside of NLP. Based on\n",
      "these ﬁndings, we describe the beginnings of a\n",
      "path forward by proposing three recommenda-\n",
      "tions that should guide work analyzing “bias”\n",
      "in NLP systems. These recommendations rest\n",
      "on a greater recognition of the relationships\n",
      "between\n",
      "language\n",
      "and\n",
      "social\n",
      "hierarchies,\n",
      "encouraging\n",
      "researchers\n",
      "and\n",
      "practitioners\n",
      "to\n",
      "articulate\n",
      "their\n",
      "conceptualizations\n",
      "of\n",
      "“bias”—i.e., what kinds of system behaviors\n",
      "are harmful, in what ways, to whom, and why,\n",
      "as well as the normative reasoning underlying\n",
      "these statements—and to center work around\n",
      "the lived experiences of members of commu-\n",
      "nities affected by NLP systems, while inter-\n",
      "rogating and reimagining the power relations\n",
      "between technologists and such communities.\n",
      "1\n",
      "Introduction\n",
      "A large body of work analyzing “bias” in natural\n",
      "language processing (NLP) systems has emerged\n",
      "in recent years, including work on “bias” in embed-\n",
      "ding spaces (e.g., Bolukbasi et al., 2016a; Caliskan\n",
      "et al., 2017; Gonen and Goldberg, 2019; May\n",
      "et al., 2019) as well as work on “bias” in systems\n",
      "developed for a breadth of tasks including language\n",
      "modeling (Lu et al., 2018; Bordia and Bowman,\n",
      "2019), coreference resolution (Rudinger et al.,\n",
      "2018; Zhao et al., 2018a), machine translation (Van-\n",
      "massenhove et al., 2018; Stanovsky et al., 2019),\n",
      "sentiment analysis (Kiritchenko and Mohammad,\n",
      "2018), and hate speech/toxicity detection (e.g.,\n",
      "Park et al., 2018; Dixon et al., 2018), among others.\n",
      "Although these papers have laid vital ground-\n",
      "work by illustrating some of the ways that NLP\n",
      "systems can be harmful, the majority of them fail\n",
      "to engage critically with what constitutes “bias”\n",
      "in the ﬁrst place. Despite the fact that analyzing\n",
      "“bias” is an inherently normative process—in\n",
      "which some system behaviors are deemed good\n",
      "and others harmful—papers on “bias” in NLP\n",
      "systems are rife with unstated assumptions about\n",
      "what kinds of system behaviors are harmful, in\n",
      "what ways, to whom, and why. Indeed, the term\n",
      "“bias” (or “gender bias” or “racial bias”) is used\n",
      "to describe a wide range of system behaviors, even\n",
      "though they may be harmful in different ways, to\n",
      "different groups, or for different reasons. Even\n",
      "papers analyzing “bias” in NLP systems developed\n",
      "for the same task often conceptualize it differently.\n",
      "For example, the following system behaviors\n",
      "are all understood to be self-evident statements of\n",
      "“racial bias”: (a) embedding spaces in which embed-\n",
      "dings for names associated with African Americans\n",
      "are closer (compared to names associated with\n",
      "European Americans) to unpleasant words than\n",
      "pleasant words (Caliskan et al., 2017); (b) senti-\n",
      "ment analysis systems yielding different intensity\n",
      "scores for sentences containing names associated\n",
      "with African Americans and sentences containing\n",
      "names associated with European Americans (Kir-\n",
      "itchenko and Mohammad, 2018); and (c) toxicity\n",
      "arXiv:2005.14050v2  [cs.CL]  29 May 2020\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'format': 'PDF 1.5',\n",
       " 'title': 'Language (Technology) is Power: A Critical Survey of “Bias” in NLP',\n",
       " 'author': 'Su Lin Blodgett, Solon Baracas, Hal Daumé III, Hanna Wallach',\n",
       " 'subject': 'A Critical Survey of Bias in NLP Systems',\n",
       " 'keywords': '',\n",
       " 'creator': 'LaTeX with hyperref package',\n",
       " 'producer': 'pdfTeX-1.40.17',\n",
       " 'creationDate': 'D:20200601004146Z',\n",
       " 'modDate': 'D:20200601004146Z',\n",
       " 'trapped': '',\n",
       " 'encryption': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF_FILE_PATH = \"/Users/sir/Downloads/Data/PDF/test/A_Critical_Survey_of_Bias_in_NLP.pdf\" \n",
    "doc = fitz.open(PDF_FILE_PATH)\n",
    "\n",
    "doc.metadata['title'] = 'Language (Technology) is Power: A Critical Survey of “Bias” in NLP'\n",
    "doc.metadata['author'] = 'Su Lin Blodgett, Solon Baracas, Hal Daumé III, Hanna Wallach'\n",
    "doc.metadata['subject'] = 'A Critical Survey of Bias in NLP Systems'\n",
    "\n",
    "## Accessing Title and Author\n",
    "\n",
    "# 1. Get the document's metadata dictionary\n",
    "metadata = doc.metadata\n",
    "\n",
    "# 2. Extract the 'title' and 'author' keys\n",
    "title = metadata.get('title', 'N/A')\n",
    "author = metadata.get('author', 'N/A')\n",
    "\n",
    "# 3. Print the results\n",
    "print(f\"Document Title: {title}\")\n",
    "print(f\"Document Author: {author}\")\n",
    "\n",
    "print(f\"PDF File Path: {PDF_FILE_PATH}\")\n",
    "\n",
    "# Access text or other content from a page (0-based index)\n",
    "page = doc.load_page(0)\n",
    "text = page.get_text()\n",
    "print(\"\\n\",text)\n",
    "\n",
    "# Don't forget to close the document\n",
    "doc.close()\n",
    "\n",
    "doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37567e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating summary with Llama-3.1-Instruct...\n",
      "\n",
      "--- GENERATED SUMMARY ---\n",
      "The article \"Language (Technology) is Power: A Critical Survey of \"Bias\" in NLP\"\n",
      "by Solon Barocas, Hal Daumé III, Hanna Wallach, and Solon Blodgett, explores the\n",
      "concept of \"bias\" in natural language processing (NLP) systems. The authors find\n",
      "that the field of NLP research on bias is often vague, inconsistent, and lacking\n",
      "in normative reasoning, despite the fact that analyzing bias is a normative\n",
      "process.  The authors conclude that papers on bias in NLP systems often fail to\n",
      "articulate the motivations behind their findings and do not engage with relevant\n",
      "literature outside of NLP. They propose three recommendations to improve the\n",
      "field:  1. **Recognize the relationships between language and social\n",
      "hierarchies**: The authors suggest that researchers and practitioners should\n",
      "articulate their conceptualizations of \"bias\" in NLP systems, including what\n",
      "kinds of system behaviors are harmful, in what ways, to whom, and why, as well\n",
      "as the normative reasoning underlying these statements. 2. **Center work around\n",
      "the lived experiences of communities affected by NLP systems**: The authors\n",
      "advocate for researchers and practitioners to engage with the lived experiences\n",
      "of members of communities affected by NLP systems, including interrogating and\n",
      "reimagining the power relations between technologists and these communities. 3.\n",
      "**Engage with the literature outside of NLP**: The authors recommend that papers\n",
      "on bias in NLP systems should be grounded in a broader understanding of the\n",
      "social and cultural contexts in which NLP systems operate, rather than relying\n",
      "solely on NLP-specific research.  Overall, the authors aim to contribute to a\n",
      "critical examination of the concept of bias in NLP systems and to promote a more\n",
      "nuanced understanding of the power dynamics at play in NLP research and\n",
      "development.\n"
     ]
    }
   ],
   "source": [
    "# prompt construction\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Summarize the following text:\n",
    "\n",
    "{text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "input = generator_tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "# --- Tokenizer Configuration ---\n",
    "# Ensure pad_token_id is set before tokenizing or generating\n",
    "if generator_tokenizer.pad_token_id is None:\n",
    "    generator_tokenizer.pad_token_id = generator_tokenizer.eos_token_id\n",
    "\n",
    "# Define the terminators for Llama 3.1\n",
    "terminators = [\n",
    "    generator_tokenizer.eos_token_id,\n",
    "    generator_tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "# --- Generate text ---\n",
    "print(\"\\nGenerating summary with Llama-3.1-Instruct...\")\n",
    "with torch.no_grad():\n",
    "    outputs = generator_model.generate(\n",
    "        **input,\n",
    "        max_new_tokens=750,        \n",
    "        do_sample=True,\n",
    "        # Increase temperature slightly for stability on bfloat16/MPS\n",
    "        temperature=0.7,             # Standard, moderate randomness\n",
    "        top_p=0.9,                  \n",
    "        # Use the list of terminators for Llama 3.1\n",
    "        eos_token_id=terminators,    # Use the list of terminators\n",
    "        pad_token_id=generator_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# 1. Decode the raw text\n",
    "output_token_ids = outputs[0][len(input['input_ids'][0]):]\n",
    "raw_output = generator_tokenizer.decode(output_token_ids, skip_special_tokens=True)\n",
    "\n",
    "# 2. Clean the output\n",
    "response_only = raw_output.strip()\n",
    "\n",
    "# 3. Wrap and print the final, correct summary\n",
    "formatted_text = textwrap.fill(response_only, width=80)\n",
    "print(\"\\n--- GENERATED SUMMARY ---\")\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58289f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Title: Deep Boosting\n",
      "Document Author: Corinna Cortes, Mehryar Mohri, Umar Syed\n",
      "PDF File Path: /Users/sir/Downloads/Data/PDF/test/DeepBoost.pdf\n",
      "\n",
      " Deep Boosting\n",
      "Corinna Cortes\n",
      "CORINNA@GOOGLE.COM\n",
      "Google Research, 111 8th Avenue, New York, NY 10011\n",
      "Mehryar Mohri\n",
      "MOHRI@CIMS.NYU.EDU\n",
      "Courant Institute and Google Research, 251 Mercer Street, New York, NY 10012\n",
      "Umar Syed\n",
      "USYED@GOOGLE.COM\n",
      "Google Research, 111 8th Avenue, New York, NY 10011\n",
      "Abstract\n",
      "We present a new ensemble learning algorithm,\n",
      "DeepBoost, which can use as base classiﬁers a\n",
      "hypothesis set containing deep decision trees, or\n",
      "members of other rich or complex families, and\n",
      "succeed in achieving high accuracy without over-\n",
      "ﬁtting the data. The key to the success of the al-\n",
      "gorithm is a capacity-conscious criterion for the\n",
      "selection of the hypotheses. We give new data-\n",
      "dependent learning bounds for convex ensembles\n",
      "expressed in terms of the Rademacher complexi-\n",
      "ties of the sub-families composing the base clas-\n",
      "siﬁer set, and the mixture weight assigned to each\n",
      "sub-family. Our algorithm directly beneﬁts from\n",
      "these guarantees since it seeks to minimize the\n",
      "corresponding learning bound. We give a full de-\n",
      "scription of our algorithm, including the details\n",
      "of its derivation, and report the results of several\n",
      "experiments showing that its performance com-\n",
      "pares favorably to that of AdaBoost and Logistic\n",
      "Regression and their L1-regularized variants.\n",
      "1. Introduction\n",
      "Ensemble methods are general techniques in machine\n",
      "learning for combining several predictors or experts to\n",
      "create a more accurate one.\n",
      "In the batch learning set-\n",
      "ting, techniques such as bagging, boosting, stacking, error-\n",
      "correction techniques, Bayesian averaging, or other av-\n",
      "eraging schemes are prominent instances of these meth-\n",
      "ods (Breiman, 1996; Freund & Schapire, 1997; Smyth &\n",
      "Wolpert, 1999; MacKay, 1991; Freund et al., 2004). En-\n",
      "semble methods often signiﬁcantly improve performance\n",
      "in practice (Quinlan, 1996; Bauer & Kohavi, 1999; Caru-\n",
      "ana et al., 2004; Dietterich, 2000; Schapire, 2003) and ben-\n",
      "Proceedings of the 31 st International Conference on Machine\n",
      "Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copy-\n",
      "right 2014 by the author(s).\n",
      "eﬁt from favorable learning guarantees. In particular, Ad-\n",
      "aBoost and its variants are based on a rich theoretical anal-\n",
      "ysis, with performance guarantees in terms of the margins\n",
      "of the training samples (Schapire et al., 1997; Koltchinskii\n",
      "& Panchenko, 2002).\n",
      "Standard ensemble algorithms such as AdaBoost combine\n",
      "functions selected from a base classiﬁer hypothesis set H.\n",
      "In many successful applications of AdaBoost, H is reduced\n",
      "to the so-called boosting stumps, that is decision trees of\n",
      "depth one.\n",
      "For some difﬁcult tasks in speech or image\n",
      "processing, simple boosting stumps are not sufﬁcient to\n",
      "achieve a high level of accuracy. It is tempting then to use\n",
      "a more complex hypothesis set, for example the set of all\n",
      "decision trees with depth bounded by some relatively large\n",
      "number. But, existing learning guarantees for AdaBoost\n",
      "depend not only on the margin and the number of the\n",
      "training examples, but also on the complexity of H mea-\n",
      "sured in terms of its VC-dimension or its Rademacher com-\n",
      "plexity (Schapire et al., 1997; Koltchinskii & Panchenko,\n",
      "2002).\n",
      "These learning bounds become looser when us-\n",
      "ing too complex base classiﬁer sets H. They suggest a\n",
      "risk of overﬁtting which indeed can be observed in some\n",
      "experiments with AdaBoost (Grove & Schuurmans, 1998;\n",
      "Schapire, 1999; Dietterich, 2000; R¨atsch et al., 2001b).\n",
      "This paper explores the design of alternative ensemble al-\n",
      "gorithms using as base classiﬁers a hypothesis set H that\n",
      "may contain very deep decision trees, or members of some\n",
      "other very rich or complex families, and that can yet suc-\n",
      "ceed in achieving a higher performance level. Assume that\n",
      "the set of base classiﬁers H can be decomposed as the\n",
      "union of p disjoint families H1, . . . , Hp ordered by increas-\n",
      "ing complexity, where Hk, k 2 [1, p], could be for example\n",
      "the set of decision trees of depth k, or a set of functions\n",
      "based on monomials of degree k. Figure 1 shows a pictorial\n",
      "illustration. Of course, if we strictly conﬁne ourselves to\n",
      "using hypotheses belonging only to families Hk with small\n",
      "k, then we are effectively using a smaller base classiﬁer set\n",
      "H with favorable guarantees. But, to succeed in some chal-\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'format': 'PDF 1.4',\n",
       " 'title': 'Deep Boosting',\n",
       " 'author': 'Corinna Cortes, Mehryar Mohri, Umar Syed',\n",
       " 'subject': '',\n",
       " 'keywords': 'ensemble methods, learning theory, boosting',\n",
       " 'creator': 'LaTeX with hyperref package',\n",
       " 'producer': 'Mac OS X 10.9.2 Quartz PDFContext',\n",
       " 'creationDate': \"D:20140513025941Z00'00'\",\n",
       " 'modDate': \"D:20140513025941Z00'00'\",\n",
       " 'trapped': '',\n",
       " 'encryption': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF_FILE_PATH = \"/Users/sir/Downloads/Data/PDF/test/DeepBoost.pdf\" \n",
    "doc = fitz.open(PDF_FILE_PATH)\n",
    "\n",
    "## Accessing Title and Author\n",
    "\n",
    "# 1. Get the document's metadata dictionary\n",
    "metadata = doc.metadata\n",
    "\n",
    "# 2. Extract the 'title' and 'author' keys\n",
    "title = metadata.get('title', 'N/A')\n",
    "author = metadata.get('author', 'N/A')\n",
    "\n",
    "# 3. Print the results\n",
    "print(f\"Document Title: {title}\")\n",
    "print(f\"Document Author: {author}\")\n",
    "\n",
    "print(f\"PDF File Path: {PDF_FILE_PATH}\")\n",
    "\n",
    "# Access text or other content from a page (0-based index)\n",
    "page = doc.load_page(0)\n",
    "text = page.get_text()\n",
    "print(\"\\n\",text)\n",
    "\n",
    "# Don't forget to close the document\n",
    "doc.close()\n",
    "\n",
    "doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "405f1595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading full text from '/Users/sir/Downloads/Data/PDF/test/DeepBoost.pdf'...\n",
      "Extraction stop found immediately before: 'References'\n",
      "Successfully extracted and cleaned 35873 characters.\n",
      "\n",
      "--- PDF TEXT ---\n",
      "We present a new ensemble learning algorithm, DeepBoost, which can use as base classiﬁers a hypothesis set containing\n",
      "deep decision trees, or members of other rich or complex families, and succeed in achieving high accuracy without over-\n",
      "ﬁtting the data. The key to the success of the algorithm is a capacityconscious criterion for the selection of the\n",
      "hypotheses. We give new datadependent learning bounds for convex ensembles expressed in terms of the Rademacher\n",
      "complexities of the subfamilies composing the base classiﬁer set, and the mixture weight assigned to each subfamily. Our\n",
      "algorithm directly beneﬁts from these guarantees since it seeks to minimize the corresponding learning bound. We give a\n",
      "full description of our algorithm, including the details of its derivation, and report the results of several\n",
      "experiments showing that its performance compares favorably to that of AdaBoost and Logistic Regression and their\n",
      "L1-regularized variants. 1. Introduction Ensemble methods are general techniques in machine learning for combining\n",
      "several predictors or experts to create a more accurate one. In the batch learning setting, techniques such as bagging,\n",
      "boosting, stacking, errorcorrection techniques, Bayesian averaging, or other averaging schemes are prominent instances\n",
      "of these methods. Ensemble methods often signiﬁcantly improve performance in practice and benProceedings of the 31 st\n",
      "International Conference on Machine Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the\n",
      "author(s). eﬁt from favorable learning guarantees. In particular, AdaBoost and its variants are based on a rich\n",
      "theoretical analysis, with performance guarantees in terms of the margins of the training samples. Standard ensemble\n",
      "algorithms such as AdaBoost combine functions selected from a base classiﬁer hypothesis set H. In many successful\n",
      "applications of AdaBoost, H is reduced to the socalled boosting stumps, that is decision trees of depth one. For some\n",
      "difﬁcult tasks in speech or image processing, simple boosting stumps are not sufﬁcient to achieve a high level of\n",
      "accuracy. It is tempting then to use a more complex hypothesis set, for example the set of all decision trees with depth\n",
      "bounded by some relatively large number. But, existing learning guarantees for AdaBoost depend not only on the margin\n",
      "and the number of the training examples, but also on the complexity of H measured in terms of its VCdimension or its\n",
      "Rademacher complexity. These learning bounds become looser when using too complex base classiﬁer sets H. They suggest a\n",
      "risk of overﬁtting which indeed can be observed in some experiments with AdaBoost. This paper explores the design of\n",
      "alternative ensemble algorithms using as base classiﬁers a hypothesis set H that may contain very deep decision trees,\n",
      "or members of some other very rich or complex families, and that can yet succeed in achieving a higher performance\n",
      "level. Assume that the set of base classiﬁers H can be decomposed as the union of p disjoint families H1, . . . , Hp\n",
      "ordered by increasing complexity, where Hk, k 2 [1, p], could be for example the set of decision trees of depth k, or a\n",
      "set of functions based on monomials of degree k. Figure 1 shows a pictorial illustration. Of course, if we strictly\n",
      "conﬁne ourselves to using hypotheses belonging only to families Hk with small k, then we are effectively using a smaller\n",
      "base classiﬁer set H with favorable guarantees. But, to succeed in some chalDeep Boosting H1 H2 H3 H4 H5 H1 H1[H2 · · ·\n",
      "H1[· · · [Hp Figure 1. Base classiﬁer set H decomposed in terms of subfamilies H1, . . . , Hp or their unions. lenging\n",
      "tasks, the use of a few more complex hypotheses could be needed. The main idea behind the design of our algorithms is\n",
      "that an ensemble based on hypotheses drawn from H1, . . . , Hp can achieve a higher accuracy by making use of hypotheses\n",
      "drawn from Hks with large k if it allocates more weights to hypotheses drawn from Hks with a small k. But, can we\n",
      "determine quantitatively the amounts of mixture weights apportioned to different families? Can we provide learning\n",
      "guarantees for such algorithms? Note that our objective is somewhat reminiscent of that of model selection, in\n",
      "particular Structural Risk Minimization (SRM) (Vapnik, 1998), but it differs from that in that we do not wish to limit\n",
      "our base classiﬁer set to some optimal Hq = Sq k=1 Hk. Rather, we seek the freedom of using as base hypotheses even\n",
      "relatively deep trees from rich Hks, with the promise of doing so infrequently, or that of reserving them a somewhat\n",
      "small weight contribution. This provides the ﬂexibility of learning with deep hypotheses. We present a new algorithm,\n",
      "DeepBoost, whose design is precisely guided by the ideas just discussed. Our algorithm is grounded in a solid\n",
      "theoretical analysis that we present in Section 2. We give new datadependent learning bounds for convex ensembles. These\n",
      "guarantees are expressed in terms of the Rademacher complexities of the subfamilies Hk and the mixture weight assigned\n",
      "to each Hk, in addition to the familiar margin terms and sample size. Our capacityconscious algorithm is derived via the\n",
      "application of a coordinate descent technique seeking to minimize such learning bounds. We give a full description of\n",
      "our algorithm, including the details of its derivation and its pseudocode (Section 3) and discuss its connection with\n",
      "previous boostingstyle algorithms. We also report the results of several experiments (Section 4) demonstrating that its\n",
      "performance compares favorably to that of AdaBoost, which is known to be one of the most competitive binary classiﬁ-\n",
      "cation algorithms. 2. Datadependent learning guarantees for convex ensembles with multiple hypothesis sets Nonnegative\n",
      "linear combination ensembles such as boosting or bagging typically assume that base functions are selected from the same\n",
      "hypothesis set H. Marginbased generalization bounds were given for ensembles of base functions taking values in {−1, +1}\n",
      "by Schapire et al. (1997) in terms of the VCdimension of H. Tighter margin bounds with simpler proofs were later given\n",
      "by Koltchinskii & Panchenko (2002), see also (Bartlett & Mendelson, 2002), for the more general case of a family H\n",
      "taking arbitrary real values, in terms of the Rademacher complexity of H. Here, we also consider base hypotheses taking\n",
      "arbitrary real values but assume that they can be selected from several distinct hypothesis sets H1, . . . , Hp with p\n",
      "≥1 and present marginbased learning in terms of the Rademacher complexity of these sets. Remarkably, the complexity term\n",
      "of these bounds admits an explicit dependency in terms of the mixture coefﬁcients deﬁning the ensembles. Thus, the\n",
      "ensemble family we consider is F = conv(Sp k=1 Hk), that is the family of functions f of the form f = PT t=1 ↵tht, where\n",
      "↵= (↵1, . . . , ↵T ) is in the simplex ∆and where, for each t 2 [1, T], ht is in Hkt for some kt 2 [1, p]. Let X denote\n",
      "the input space. H1, . . . , Hp are thus families of functions mapping from X to R. We consider the familiar supervised\n",
      "learning scenario and assume that training and test points are drawn i.i.d. according to some distribution D over X\n",
      "⇥{−1, +1} and denote by S = ((x1, y1), . . . , (xm, ym)) a training sample of size m drawn according to Dm. Let ⇢> 0.\n",
      "For a function f taking values in R, we denote by R(f) its binary classiﬁcation error, by R⇢(f) its ⇢-margin error, and\n",
      "by bRS,⇢(f) its empirical margin error: R(f) = E (x,y)⇠D[1yf(x)0], R⇢(f) = E (x,y)⇠D[1yf(x)⇢], bR⇢(f) = E\n",
      "(x,y)⇠S[1yf(x)⇢], where the notation (x, y) ⇠S indicates that (x, y) is drawn according to the empirical distribution\n",
      "deﬁned by S. The following theorem gives a marginbased Rademacher complexity bound for learning with such functions in\n",
      "the binary classiﬁcation case. As with other Rademacher complexity learning guarantees, our bound is datadependent,\n",
      "which is an important and favorable characteristic of our results. For p = 1, that is for the special case of a single\n",
      "hypothesis set, the analysis coincides with that of the standard ensemble margin bounds (Koltchinskii & Panchenko,\n",
      "2002). Theorem 1. Assume p > 1. Fix ⇢> 0. Then, for any δ > 0, with probability at least 1 −δ over the choice of a\n",
      "sample S of size m drawn i.i.d. according to Dm, the following inequality holds for all f = PT t=1 ↵tht 2 F: R(f)\n",
      "bRS,⇢(f) + 4 ⇢ T X t=1 ↵tRm(Hkt) + 2 ⇢ r log p m + s⇠4 ⇢2 log h ⇢2m log p i⇡log p m + log 2 δ 2m . Deep Boosting Thus,\n",
      "R(f) bRS,⇢(f) + 4 ⇢ PT t=1 ↵tRm(Hkt) + C(m, p) with C(m, p) = O ⇣q log p ⇢2m log ⇥⇢2m log p ⇤⌘ . This result is\n",
      "remarkable since the complexity term in the righthand side of the bound admits an explicit dependency on the mixture\n",
      "coefﬁcients ↵t. It is a weighted average of Rademacher complexities with mixture weights ↵t, t 2 [1, T]. Thus, the\n",
      "second term of the bound suggests that, while some hypothesis sets Hk used for learning could have a large Rademacher\n",
      "complexity, this may not be detrimental to generalization if the corresponding total mixture weight (sum of ↵ts\n",
      "corresponding to that hypothesis set) is relatively small. Such complex families offer the potential of achieving a\n",
      "better margin on the training sample. The theorem cannot be proven via a standard Rademacher complexity analysis such as\n",
      "that of Koltchinskii & Panchenko (2002) since the complexity term of the bound would then be the Rademacher complexity\n",
      "of the family of hypotheses F = conv(Sp k=1 Hk) and would not depend on the speciﬁc weights ↵t deﬁning a given function\n",
      "f. Furthermore, the complexity term of a standard Rademacher complexity analysis is always lower bounded by the\n",
      "complexity term appearing in our bound. Indeed, since Rm(conv([p k=1Hk)) = Rm([p k=1Hk), the following lower bound holds\n",
      "for any choice of the nonnegative mixtures weights ↵t summing to one: Rm(F) ≥ m max k=1 Rm(Hk) ≥ T X t=1 ↵tRm(Hkt). (1)\n",
      "Thus, Theorem 1 provides a ﬁner learning bound than the one obtained via a standard Rademacher complexity analysis. The\n",
      "full proof of the theorem is given in Appendix A. Our proof technique exploits standard tools used to derive Rademacher\n",
      "complexity learning bounds (Koltchinskii & Panchenko, 2002) as well as a technique used by Schapire, Freund, Bartlett,\n",
      "and Lee (1997) to derive early VCdimension margin bounds. Using other standard techniques as in, Theorem 1 can be\n",
      "straightforwardly generalized to hold uniformly for all ⇢> 0 at the price of an additional term that is in O ⇣q log log\n",
      "2 ⇢ m ⌘ . 3. Algorithm In this section, we will use the learning guarantees of Section 2 to derive a capacityconscious\n",
      "ensemble algorithm for binary classiﬁcation. 3.1. Optimization problem Let H1, . . . , Hp be p disjoint families of\n",
      "functions taking values in [−1, +1] with increasing Rademacher complexities Rm(Hk), k 2 [1, p]. We will assume that the\n",
      "hypothesis sets Hk are symmetric, that is, for any h 2 Hk, we also have (−h) 2 Hk, which holds for most hypothesis sets\n",
      "typically considered in practice. This assumption is not necessary but it helps simplifying the presentation of our\n",
      "algorithm. For any hypothesis h 2 [p k=1Hk, we denote by d(h) the index of the hypothesis set it belongs to, that is h 2\n",
      "Hd(h). The bound of Theorem 1 holds uniformly for all ⇢> 0 and functions f 2 conv(Sp k=1 Hk).1 Since the last term of\n",
      "the bound does not depend on ↵, it suggests selecting ↵to minimize G(↵) = 1 m m X i=1 1yi PT t=1 ↵tht(xi)⇢+ 4 ⇢ T X t=1\n",
      "↵trt, where rt = Rm(Hd(ht)). Since for any ⇢> 0, f and f/⇢ admit the same generalization error, we can instead search\n",
      "for ↵≥0 with PT t=1 ↵t 1/⇢which leads to min ↵≥0 1 m m X i=1 1yi PT t=1↵tht(xi)1+4 T X t=1 ↵trt s.t. T X t=1 ↵t 1 ⇢.\n",
      "The ﬁrst term of the objective is not a convex function of ↵and its minimization is known to be computationally hard.\n",
      "Thus, we will consider instead a convex upper bound. Let u 7! Φ(−u) be a nonincreasing convex function upper bounding u\n",
      "7! 1u0 with Φ differentiable over R and Φ0(u) 6= 0 for all u. Φ may be selected to be for example the exponential\n",
      "function as in AdaBoost (Freund & Schapire, 1997) or the logistic function. Using such an upper bound, we obtain the\n",
      "following convex optimization problem: min ↵≥0 1 m m X i=1 Φ ⇣ 1 −yi T X t=1 ↵tht(xi) ⌘ + λ T X t=1 ↵trt (2) s.t. T X\n",
      "t=1 ↵t 1 ⇢, where we introduced a parameter λ ≥0 controlling the balance between the magnitude of the values taken by\n",
      "function Φ and the second term. Introducing a Lagrange variable β ≥0 associated to the constraint in (2), the problem\n",
      "can be equivalently written as min ↵≥0 1 m m X i=1 Φ ⇣ 1 −yi T X t=1 ↵tht(xi) ⌘ + T X t=1 (λrt + β)↵t. Here, β is a\n",
      "parameter that can be freely selected by the algorithm since any choice of its value is equivalent to a 1The condition\n",
      "PT t=1 ↵t = 1 of Theorem 1 can be relaxed to PT t=1 ↵t 1. To see this, use for example a null hypothesis (ht = 0 for\n",
      "some t). Deep Boosting choice of ⇢in (2). Let {h1, . . . , hN} be the set of distinct base functions, and let G be the\n",
      "objective function based on that collection: G(↵)= 1 m m X i=1 Φ ⇣ 1−yi N X j=1 ↵jhj(xi) ⌘ + N X t=1 (λrj+β)↵j, with ↵=\n",
      "(↵1, . . . , ↵N) 2 RN. Note that we can drop the requirement ↵≥0 since the hypothesis sets are symmetric and ↵tht =\n",
      "(−↵t)(−ht). For each hypothesis h, we keep either h or −h in {h1, . . . , hN}. Using the notation ⇤j = λrj + β, (3) for\n",
      "all j 2 [1, N], our optimization problem can then be rewritten as min↵F(↵) with F(↵)= 1 m m X i=1 Φ ⇣ 1−yi N X j=1\n",
      "↵jhj(xi) ⌘ + N X t=1 ⇤j|↵j|, (4) with no nonnegativity constraint on ↵. The function F is convex as a sum of convex\n",
      "functions and admits a subdifferential at all ↵2 R. We can design a boostingstyle algorithm by applying coordinate\n",
      "descent to F(↵). Let ↵t = (↵t,1, . . . , ↵t,N)> denote the vector obtained after t ≥1 iterations and let ↵0 = 0. Let ek\n",
      "denote the kth unit vector in RN, k 2 [1, N]. The direction ek and the step ⌘selected at the tth round are those\n",
      "minimizing F(↵t−1 + ⌘ek), that is F(↵t−1 + ⌘ek)= 1 m m X i=1 Φ ⇣ 1 −yift−1(xi)−⌘yihk(xi) ⌘ + X j6=k ⇤j|↵t−1,j| +\n",
      "⇤k|↵t−1,k + ⌘|, where ft−1 = PN j=1 ↵t−1,jhj. For any t 2 [1, T], we denote by Dt the distribution deﬁned by Dt(i) = Φ00\n",
      "1 −yift−1(xi) 1 St , (5) where St is a normalization factor, St = Pm i=1 Φ0(1 − yift−1(xi)). For any s 2 [1, T] and j 2\n",
      "[1, N], we denote by ✏s,j the weighted error of hypothesis hj for the distribution Ds, for s 2 [1, T]: ✏s,j = 1 2 h 1 −\n",
      "E i⇠Ds[yihj(xi)] i . (6) 3.2. DeepBoost Figure 2 shows the pseudocode of the algorithm DeepBoost derived by applying\n",
      "coordinate descent to the objective function (4). The details of the derivation of the expression are given in Appendix\n",
      "B. In the special cases of the DEEPBOOST(S = ((x1, y1), . . . , (xm, ym))) 1 for i 1 to m do 2 D1(i) 1 m 3 for t 1 to T\n",
      "do 4 for j 1 to N do 5 if (↵t−1,j 6= 0) then 6 dj 0 ✏t,j −1 2 1 + sgn(↵t−1,j) ⇤jm 2St 7 elseif 022✏t,j −1 2 22 ⇤jm 2St\n",
      "1 then 8 dj 0 9 else dj 0 ✏t,j −1 2 1 −sgn(✏t,j −1 2) ⇤jm 2St 10 k argmax j2[1,N] |dj| 11 ✏t ✏t,k 12 if 0 |(1\n",
      "−✏t)e↵t−1,k −✏te−↵t−1,k|⇤km St 1 then 13 ⌘t −↵t−1,k 14 elseif 0 (1 −✏t)e↵t−1,k −✏te−↵t−1,k > ⇤km St 1 then 15 ⌘t log h\n",
      "−⇤km 2✏tSt + q⇥⇤km 2✏tSt ⇤2+ 1−✏t ✏t i 16 else ⌘t log h + ⇤km 2✏tSt + q⇥⇤km 2✏tSt ⇤2+ 1−✏t ✏t i 17 ↵t ↵t−1 + ⌘tek 18\n",
      "St+1 Pm i=1 Φ00 1 −yi PN j=1 ↵t,jhj(xi) 1 19 for i 1 to m do 20 Dt+1(i) Φ00 1−yi PN j=1 ↵t,jhj(xi) 1 St+1 21 f PN j=1\n",
      "↵T,jhj 22 return f Figure 2. Pseudocode of the DeepBoost algorithm for both the exponential loss and the logistic loss.\n",
      "The expression of the weighted error ✏t,j is given in (6). In the generic case of a surrogate loss Φ different from the\n",
      "exponential or logistic losses, ⌘t is found instead via a line search or other numerical methods from ⌘t = argmax⌘F(↵t−1\n",
      "+ ⌘ek). exponential loss (Φ(−u) = exp(−u)) or the logistic loss (Φ(−u) = log2(1 + exp(−u))), a closedform expression is\n",
      "given for the step size (lines 12-16), which is the same in both cases (see Sections B.4 and B.5). In the generic case,\n",
      "the step size ⌘t can be found using a line search or other numerical methods. Note that when the condition of line 12 is\n",
      "satisﬁed, the step taken by the algorithm cancels out the coordinate along the direction k, thereby leading to a sparser\n",
      "result. This is consistent with the fact that the objective function contains a second term based on (weighted) L1-norm,\n",
      "which is favoring sparsity. Our algorithm is related to several other boostingtype algorithms devised in the past. For λ\n",
      "= 0 and β = 0 and using the exponential surrogate loss, it coincides with AdaBoost (Freund & Schapire, 1997) with\n",
      "precisely the same direction and same step log hq 1−✏t ✏t i using H = Sp k=1 Hk as the hypothesis set for base learners.\n",
      "This corresponds to Deep Boosting ignoring the complexity term of our bound as well as the control of the sum of the\n",
      "mixture weights via β. For λ = 0 and β = 0 and using the logistic surrogate loss, our algorithm also coincides with\n",
      "additive logistic loss. In the special case where λ = 0 and β 6= 0 and for the exponential surrogate loss, our algorithm\n",
      "matches the L1-norm regularized AdaBoost (e.g., see). For the same choice of the parameters and for the logistic\n",
      "surrogate loss, our algorithm matches the L1- norm regularized additive Logistic Regression studied by Duchi & Singer\n",
      "(2009) using the base learner hypothesis set H = Sp k=1 Hk. H may in general be very rich. The key foundation of our\n",
      "algorithm and analysis is instead to take into account the relative complexity of the subfamilies Hk. Also, note that\n",
      "L1-norm regularized AdaBoost and Logistic Regression can be viewed as algorithms minimizing the learning bound obtained\n",
      "via the standard Rademacher complexity analysis (Koltchinskii & Panchenko, 2002), using the exponential or logistic\n",
      "surrogate losses. Instead, the objective function minimized by our algorithm is based on the generalization bound of\n",
      "Theorem 1, which as discussed earlier is a ﬁner bound (see (1)). For λ = 0 but β 6= 0, our algorithm is also close to\n",
      "the socalled unnormalized Arcing (Breiman, 1999) or AdaBoost⇢(R¨atsch & Warmuth, 2002) using H as a hypothesis set.\n",
      "AdaBoost⇢coincides with AdaBoost modulo the step size, which is more conservative than that of AdaBoost and depends on\n",
      "⇢. R¨atsch & Warmuth (2005) give another variant of the algorithm that does not require knowing the best ⇢, see also the\n",
      "related work of Kivinen & Warmuth (1999); Warmuth et al. (2006). Our algorithm directly beneﬁts from the learning\n",
      "guarantees given in Section 2 since it seeks to minimize the bound of Theorem 1. In the next section, we report the\n",
      "results of our experiments with DeepBoost. Let us mention that we have also designed an alternative deep boosting\n",
      "algorithm that we brieﬂy describe and discuss in Appendix C. 4. Experiments An additional beneﬁt of the learning bounds\n",
      "presented in Section 2 is that they are datadependent. They are based on the Rademacher complexity of the base\n",
      "hypothesis sets Hk, which in some cases can be well estimated from the training sample. The algorithm DeepBoost directly\n",
      "inherits this advantage. For example, if the hypothesis set Hk is based on a positive deﬁnite kernel with sample matrix\n",
      "Kk, it is known that its empirical Rademacher complexity can be upper bounded by p Tr[Kk] m and lower bounded by 1 p 2 p\n",
      "Tr[Kk] m . In other cases, when Hk is a family of functions taking binary values, we can use an upper bound on the\n",
      "Rademacher complexity in terms of the growth function of Hk, ⇧Hk(m): Rm(Hk)  q 2 log ⇧Hk (m) m . Thus, for the family\n",
      "Hstumps 1 of boosting stumps in dimension d, ⇧Hstumps 1 (m) 2md, since there are 2m distinct threshold functions for\n",
      "each dimension with m points. Thus, the following inequality holds: Rm(Hstumps 1 )  r 2 log(2md) m . (7) Similarly, we\n",
      "consider the family of decision trees Hstumps 2 of depth 2 with the same question at the internal nodes of depth 1. We\n",
      "have ⇧Hstumps 2 (m) (2m)2 d(d−1) 2 since there are d(d −1)/2 distinct trees of this type and since each induces at most\n",
      "(2m)2 labelings. Thus, we can write Rm(Hstumps 2 )  r 2 log(2m2d(d −1)) m . (8) More generally, we also consider the\n",
      "family of all binary decision trees Htrees k of depth k. For this family it is known that VCdim(Htrees k ) (2k + 1)\n",
      "log2(d + 1) (Mansour, 1997). More generally, the VCdimension of Tn, the family of decision trees with n nodes in\n",
      "dimension d can be bounded by (2n + 1) log2(d + 2) (see for example). Since Rm(H)  q 2 VCdim(H) log(m+1) m , for any\n",
      "hypothesis class H we have Rm(Tn)  r (4n + 2) log2(d + 2) log(m + 1) m . (9) The experiments with DeepBoost described\n",
      "below use either Hstumps = Hstumps 1 [ Hstumps 2 or Htrees K = SK k=1 Htrees k , for some K > 0, as the base hypothesis\n",
      "sets. For any hypothesis in these sets, DeepBoost will use the upper bounds given above as a proxy for the Rademacher\n",
      "complexity of the set to which it belongs. We leave it to the future to experiment with ﬁner datadependent estimates or\n",
      "upper bounds on the Rademacher complexity, which could further improve the performance of our algorithm. Recall that\n",
      "each iteration of DeepBoost searches for the base hypothesis that is optimal with respect to a certain criterion (see\n",
      "lines 5-10 of Figure 2). While an exhaustive search is feasible for Hstumps 1 , it would be far too expensive to visit\n",
      "all trees in Htrees K when K is large. Therefore, when using Htrees K and also Hstumps 2 as the base hypotheses we use\n",
      "the following heuristic search procedure in each iteration t: First, the optimal tree h⇤ 1 2 Htrees 1 is found via\n",
      "exhaustive search. Next, for all 1 < k K, a locally optimal tree h⇤ k 2 Htrees k is found by considering only trees\n",
      "that can be obtained by adding a single layer of leaves to h⇤ k−1. Finally, we select the best hypotheses in the set {h⇤\n",
      "1, . . . , h⇤ K, h1, . . . , ht−1}, where h1, . . . , ht−1 are the hypotheses selected in previous iterations. Deep\n",
      "Boosting Table 1. Results for boosted decision stumps and the exponential loss function. AdaBoost AdaBoost AdaBoost\n",
      "AdaBoost breastcancer Hstumps 1 Hstumps 2 AdaBoostL1 DeepBoost ocr17 Hstumps 1 Hstumps 2 AdaBoostL1 DeepBoost Error\n",
      "0.0429 0.0437 0.0408 0.0373 Error 0.0085 0.008 0.0075 0.0070 (std dev) (0.0248) (0.0214) (0.0223) (0.0225) (std dev)\n",
      "0.0072 0.0054 0.0068 (0.0048) Avg tree size 1 2 1.436 1.215 Avg tree size 1 2 1.086 1.369 Avg no. of trees 100 100 43.6\n",
      "21.6 Avg no. of trees 100 100 37.8 36.9 AdaBoost AdaBoost AdaBoost AdaBoost ionosphere Hstumps 1 Hstumps 2 AdaBoostL1\n",
      "DeepBoost ocr49 Hstumps 1 Hstumps 2 AdaBoostL1 DeepBoost Error 0.1014 0.075 0.0708 0.0638 Error 0.0555 0.032 0.03 0.0275\n",
      "(std dev) (0.0414) (0.0413) (0.0331) (0.0394) (std dev) 0.0167 0.0114 0.0122 (0.0095) Avg tree size 1 2 1.392 1.168 Avg\n",
      "tree size 1 2 1.99 1.96 Avg no. of trees 100 100 39.35 17.45 Avg no. of trees 100 100 99.3 96 AdaBoost AdaBoost AdaBoost\n",
      "AdaBoost german Hstumps 1 Hstumps 2 AdaBoostL1 DeepBoost ocr17-mnist Hstumps 1 Hstumps 2 AdaBoostL1 DeepBoost Error\n",
      "0.243 0.2505 0.2455 0.2395 Error 0.0056 0.0048 0.0046 0.0040 (std dev) (0.0445) (0.0487) (0.0438) (0.0462) (std dev)\n",
      "0.0017 0.0014 0.0013 (0.0014) Avg tree size 1 2 1.54 1.76 Avg tree size 1 2 2 1.99 Avg no. of trees 100 100 54.1 76.5\n",
      "Avg no. of trees 100 100 100 100 AdaBoost AdaBoost AdaBoost AdaBoost diabetes Hstumps 1 Hstumps 2 AdaBoostL1 DeepBoost\n",
      "ocr49-mnist Hstumps 1 Hstumps 2 AdaBoostL1 DeepBoost Error 0.253 0.260 0.254 0.253 Error 0.0414 0.0209 0.0200 0.0177\n",
      "(std dev) (0.0330) (0.0518) (0.04868) (0.0510) (std dev) 0.00539 0.00521 0.00408 (0.00438) Avg tree size 1 2 1.9975\n",
      "1.9975 Avg tree size 1 2 1.9975 1.9975 Avg no. of trees 100 100 100 100 Avg no. of trees 100 100 100 100 Breiman (1999)\n",
      "and Reyzin & Schapire (2006) extensively investigated the relationship between the complexity of decision trees in an\n",
      "ensemble learned by AdaBoost and the generalization error of the ensemble. We tested DeepBoost on the same UCI datasets\n",
      "used by these authors, http:// archive.ics.uci.edu/ml/datasets.html, speciﬁ- cally breastcancer, ionosphere,\n",
      "german(numeric) and diabetes. We also experimented with two optical character recognition datasets used by Reyzin &\n",
      "Schapire (2006), ocr17 and ocr49, which contain the handwritten digits 1 and 7, and 4 and 9 (respectively). Finally,\n",
      "because these OCR datasets are fairly small, we also constructed the analogous datasets from all of MNIST,\n",
      "lecun.com/exdb/mnist/, which we call ocr17-mnist and ocr49-mnist. More details on all the datasets are given in Table 4,\n",
      "Appendix D.1. As we discussed in Section 3.2, by ﬁxing the parameters β and λ to certain values, we recover some known\n",
      "algorithms as special cases of DeepBoost. Our experiments compared DeepBoost to AdaBoost (β = λ = 0 with exponential\n",
      "loss), to Logistic Regression (β = λ = 0 with logistic loss), which we abbreviate as LogReg, to L1-norm regularized\n",
      "AdaBoost (e.g., see) abbreviated as AdaBoostL1, and also to the L1-norm regularized additive Logistic Regression\n",
      "algorithm studied by (Duchi & Singer, 2009) (β > 0, λ = 0) abbreviated as LogRegL1. In the ﬁrst set of experiments\n",
      "reported in Table 1, we compared AdaBoost, AdaBoostL1, and DeepBoost with the exponential loss (Φ(−u) = exp(−u)) and\n",
      "base hypotheses Hstumps. We tested standard AdaBoost with base hypotheses Hstumps 1 and Hstumps 2 . For AdaBoostL1, we\n",
      "optimized over β 2 {2−i : i = 6, . . . , 0} and for DeepBoost, we optimized over β in the same range and λ 2 {0.0001,\n",
      "0.005, 0.01, 0.05, 0.1, 0.5}. The exact parameter optimization procedure is described below. In the second set of\n",
      "experiments reported in Table 2, we used base hypotheses Htrees K instead of Hstumps, where the maximum tree depth K was\n",
      "an additional parameter to be optimized. Speciﬁcally, for AdaBoost we optimized over K 2 {1, . . . , 6}, for AdaBoostL1\n",
      "we optimized over those same values for K and β 2 {10−i : i = 3, . . . , 7}, and for DeepBoost we optimized over those\n",
      "same values for K, β and λ 2 {10−i : i = 3, . . . , 7}. The last set of experiments, reported in Table 3, are identical\n",
      "to the experiments reported in Table 2, except we used the logistic loss Φ(−u) = log2(1 + exp(−u)). We used the\n",
      "following parameter optimization procedure in all experiments: Each dataset was randomly partitioned into 10 folds, and\n",
      "each algorithm was run 10 times, with a different assignment of folds to the training set, validation set and test set\n",
      "for each run. Speciﬁcally, for each run i 2 {0, . . . , 9}, fold i was used for testing, fold i + 1 (mod 10) was used\n",
      "for validation, and the remaining folds were used for training. For each run, we selected the parameters that had the\n",
      "lowest error on the validation set and then measured the error of those parameters on the test set. The average error\n",
      "and the standard deviation of the error over all 10 runs is reported in Tables 1, 2 and 3, as is the average number of\n",
      "trees and the average size of the trees in the ensembles. In all of our experiments, the number of iterations was set to\n",
      "100. We also experimented with running each algorithm Deep Boosting Table 2. Results for boosted decision trees and the\n",
      "exponential loss function. breastcancer AdaBoost AdaBoostL1 DeepBoost ocr17 AdaBoost AdaBoostL1 DeepBoost Error 0.0267\n",
      "0.0264 0.0243 Error 0.004 0.003 0.002 (std dev) (0.00841) (0.0098) (0.00797) (std dev) (0.00316) (0.00100) (0.00100) Avg\n",
      "tree size 29.1 28.9 20.9 Avg tree size 15.0 30.4 26.0 Avg no. of trees 67.1 51.7 55.9 Avg no. of trees 88.3 65.3 61.8\n",
      "ionosphere AdaBoost AdaBoostL1 DeepBoost ocr49 AdaBoost AdaBoostL1 DeepBoost Error 0.0661 0.0657 0.0501 Error 0.0180\n",
      "0.0175 0.0175 (std dev) (0.0315) (0.0257) (0.0316) (std dev) (0.00555) (0.00357) (0.00510) Avg tree size 29.8 31.4 26.1\n",
      "Avg tree size 30.9 62.1 30.2 Avg no. of trees 75.0 69.4 50.0 Avg no. of trees 92.4 89.0 83.0 german AdaBoost AdaBoostL1\n",
      "DeepBoost ocr17-mnist AdaBoost AdaBoostL1 DeepBoost Error 0.239 0.239 0.234 Error 0.00471 0.00471 0.00409 (std dev)\n",
      "(0.0165) (0.0201) (0.0148) (std dev) (0.0022) (0.0021) (0.0021) Avg tree size 3 7 16.0 Avg tree size 15 33.4 22.1 Avg\n",
      "no. of trees 91.3 87.5 14.1 Avg no. of trees 88.7 66.8 59.2 diabetes AdaBoost AdaBoostL1 DeepBoost ocr49-mnist AdaBoost\n",
      "AdaBoostL1 DeepBoost Error 0.249 0.240 0.230 Error 0.0198 0.0197 0.0182 (std dev) (0.0272) (0.0313) (0.0399) (std dev)\n",
      "(0.00500) (0.00512) (0.00551) Avg tree size 3 3 5.37 Avg tree size 29.9 66.3 30.1 Avg no. of trees 45.2 28.0 19.0 Avg\n",
      "no. of trees 82.4 81.1 80.9 Table 3. Results for boosted decision trees and the logistic loss function. breastcancer\n",
      "LogReg LogRegL1 DeepBoost ocr17 LogReg LogRegL1 DeepBoost Error 0.0351 0.0264 0.0264 Error 0.00300 0.00400 0.00250 (std\n",
      "dev) (0.0101) (0.0120) (0.00876) (std dev) (0.00100) (0.00141) (0.000866) Avg tree size 15 59.9 14.0 Avg tree size 15.0\n",
      "7 22.1 Avg no. of trees 65.3 16.0 23.8 Avg no. of trees 75.3 53.8 25.8 ionosphere LogReg LogRegL1 DeepBoost ocr49 LogReg\n",
      "LogRegL1 DeepBoost Error 0.074 0.060 0.043 Error 0.0205 0.0200 0.0170 (std dev) (0.0236) (0.0219) (0.0188) (std dev)\n",
      "(0.00654) (0.00245) (0.00361) Avg tree size 7 30.0 18.4 Avg tree size 31.0 31.0 63.2 Avg no. of trees 44.7 25.3 29.5 Avg\n",
      "no. of trees 63.5 54.0 37.0 german LogReg LogRegL1 DeepBoost ocr17-mnist LogReg LogRegL1 DeepBoost Error 0.233 0.232\n",
      "0.225 Error 0.00422 0.00417 0.00399 (std dev) (0.0114) (0.0123) (0.0103) (std dev) (0.00191) (0.00188) (0.00211) Avg\n",
      "tree size 7 7 14.4 Avg tree size 15 15 25.9 Avg no. of trees 72.8 66.8 67.8 Avg no. of trees 71.4 55.6 27.6 diabetes\n",
      "LogReg LogRegL1 DeepBoost ocr49-mnist LogReg LogRegL1 DeepBoost Error 0.250 0.246 0.246 Error 0.0211 0.0201 0.0201 (std\n",
      "dev) (0.0374) (0.0356) (0.0356) (std dev) (0.00412) (0.00433) (0.00411) Avg tree size 3 3 3 Avg tree size 28.7 33.5 72.8\n",
      "Avg no. of trees 46.0 45.5 45.5 Avg no. of trees 79.3 61.7 41.9 for up to 1,000 iterations, but observed that the test\n",
      "errors did not change signiﬁcantly, and more importantly the ordering of the algorithms by their test errors was\n",
      "unchanged from 100 iterations to 1,000 iterations. Observe that with the exponential loss, DeepBoost has a smaller test\n",
      "error than AdaBoost and AdaBoostL1 on every dataset and for every set of base hypotheses, except for the ocr49-mnist\n",
      "dataset with decision trees where its performance matches that of AdaBoostL1. Similarly, with the logistic loss,\n",
      "DeepBoost performs always at least as well as LogReg or LogRegL1. For the smallsized UCI datasets it is difﬁcult to\n",
      "obtain statistically signiﬁcant results, but, for the larger ocrXXmnist datasets, our results with DeepBoost are\n",
      "statistically signiﬁcantly better at the 2% level using onesided paired ttests in all three sets of experiments (three\n",
      "tables), except for ocr49-mnist in Table 3, where this holds only for the comparison with LogReg. This acrosstheboard\n",
      "improvement is the result of DeepBoost’s complexityconscious ability to dynamically tune the sizes of the decision trees\n",
      "selected in each boosting round, trading off between training error and hypothesis class complexity. The selected tree\n",
      "sizes should depend on properties of the training set, and this is borne out by our experiments: For some datasets, such\n",
      "as breastcancer, DeepBoost selects trees that are smaller on average than the trees selected by AdaBoostL1 or LogRegL1,\n",
      "while, for other datasets, such as german, the average tree size is larger. Note that AdaBoost and AdaBoostL1 produce\n",
      "ensembles of trees that have a constant depth since neither algorithm penalizes tree size except for imposing a maximum\n",
      "tree depth K, while for DeepBoost the trees in one ensemble typically vary in size. Figure 3 plots the distriDeep\n",
      "Boosting Ion: Histogram of tree sizes Tree sizes Frequency 10 20 30 40 0 2 4 6 8 10 12 Figure 3. Distribution of tree\n",
      "sizes when DeepBoost is run on the ionosphere dataset. bution of tree sizes for one run of DeepBoost. It should be noted\n",
      "that the columns for AdaBoost in Table 1 simply list the number of stumps to be the same as the number of boosting\n",
      "rounds; a careful examination of the ensembles for 100 rounds of boosting typically reveals a 5% duplication of stumps\n",
      "in the ensembles. Theorem 1 is a marginbased generalization guarantee, and is also the basis for the derivation of\n",
      "DeepBoost, so we should expect DeepBoost to induce large margins on the training set. Figure 4 shows the margin\n",
      "distributions for AdaBoost, AdaBoostL1 and DeepBoost on the same subset of the ionosphere dataset. 5. Conclusion We\n",
      "presented a theoretical analysis of learning with a base hypothesis set composed of increasingly complex subfamilies,\n",
      "including very deep or complex ones, and derived an algorithm, DeepBoost, which is precisely based on those guarantees.\n",
      "We also reported the results of experiments with this algorithm and compared its performance with that of AdaBoost and\n",
      "additive Logistic Regression, and their L1-norm regularized counterparts in several tasks. We have derived similar\n",
      "theoretical guarantees in the multiclass setting and used them to derive a family of new multiclass deep boosting\n",
      "algorithms that we will present and discuss elsewhere. Our theoretical analysis and algorithmic design could also be\n",
      "extended to ranking and to a broad class of loss functions. This should also lead to the generalization of several\n",
      "existing algorithms and their use with a richer hypothesis set structured as a union of families with different\n",
      "Rademacher complexity. In particular, the broad family of maximum entropy models and conditional maximum entropy models\n",
      "and their many variants, which includes the already discussed logistic regression, could all be extended in a similar\n",
      "way. The resulting DeepMaxent models (or their conditional versions) may admit an alternative theoretical justiﬁcation\n",
      "that we will discuss elsewhere. Our algorithm can also be extended by considering nondifferentiable convex surrogate\n",
      "losses such as the hinge loss. When used with kernel base classiﬁers, this leads to an algorithm we have named DeepSVM.\n",
      "The theory we developed could perhaps be further generalized to Ion: AdaBoost−L1, fold = 6 Normalized Margin Frequency\n",
      "0.1 0.3 0.5 0.7 0 10 20 30 40 50 Ion: AdaBoost, fold = 6 Normalized Margin Frequency 0.1 0.3 0.5 0.7 0 10 20 30 40 50\n",
      "Ion: DeepBoost, fold = 6 Normalized Margin Frequency 0.1 0.3 0.5 0.7 0 10 20 30 40 50 0.1 0.3 0.5 0.7 0.0 0.2 0.4 0.6\n",
      "0.8 1.0 Normalized Margin Cumulative Dist. Cumulative Distribution of Margins Figure 4. Distribution of normalized\n",
      "margins for AdaBoost (upper right), AdaBoostL1 (upper left) and DeepBoost (lower left) on the same subset of ionosphere.\n",
      "The cumulative margin distributions (lower right) illustrate that DeepBoost (red) induces larger margins on the training\n",
      "set than either AdaBoost (black) or AdaBoostL1 (blue). encompass the analysis of other learning techniques such as\n",
      "multilayer neural networks. Our analysis and algorithm also shed some new light on some remaining questions left about\n",
      "the theory underlying AdaBoost. The primary theoretical justiﬁcation for AdaBoost is a margin guarantee. However,\n",
      "AdaBoost does not precisely maximize the minimum margin, while other algorithms such as arcgv (Breiman, 1996) that are\n",
      "designed to do so tend not to outperform AdaBoost (Reyzin & Schapire, 2006). Two main reasons are suspected for this\n",
      "observation: (1) in order to achieve a better margin, algorithms such as arcgv may tend to select deeper decision trees\n",
      "or in general more complex hypotheses, which may then affect their generalization; (2) while those algorithms achieve a\n",
      "better margin, they do not achieve a better margin distribution. Our theory may help better understand and evaluate the\n",
      "effect of factor (1) since our learning bounds explicitly depend on the mixture weights and the contribution of each\n",
      "hypothesis set Hk to the deﬁnition of the ensemble function. However, our guarantees also suggest a better algorithm,\n",
      "DeepBoost. Acknowledgments We thank Vitaly Kuznetsov for his comments on an earlier draft of this paper. The work of M.\n",
      "Mohri was partly funded by the NSF award IIS-1117591. Deep Boosting\n"
     ]
    }
   ],
   "source": [
    "text = get_text_from_pdf(PDF_FILE_PATH)\n",
    "print(\"\\n--- PDF TEXT ---\")\n",
    "text = textwrap.fill(text, width=120)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac56f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Generator: /Users/sir/Downloads/HuggingFace/LLM/meta-Llama-3.2-1B-Instruct\n",
      "\n",
      "Generating summary with Llama-3.1-Instruct...\n",
      "\n",
      "--- GENERATED SUMMARY ---\n",
      "The text you provided is a research paper that presents a theoretical analysis\n",
      "of a new ensemble learning algorithm called DeepBoost, which is designed to use\n",
      "a hypothesis set of increasing complexity, including very deep or complex\n",
      "hypotheses, to improve the accuracy of machine learning models. The paper also\n",
      "reports the results of experiments with DeepBoost on several datasets, including\n",
      "UCI datasets and the MNIST dataset.  Here's a summary of the key points:  **Key\n",
      "contributions:**  1. **Theoretical analysis:** The paper provides a theoretical\n",
      "analysis of the DeepBoost algorithm, which is based on a hypothesis set of\n",
      "increasing complexity, including very deep or complex hypotheses. 2. **Learning\n",
      "bounds:** The paper derives new learning bounds for the DeepBoost algorithm,\n",
      "which are based on the Rademacher complexity of the hypothesis sets and the\n",
      "mixture weights assigned to each hypothesis set. 3. **Experimental results:**\n",
      "The paper reports the results of experiments with DeepBoost on several datasets,\n",
      "including UCI datasets and the MNIST dataset. 4. **Comparison to other\n",
      "algorithms:** The paper compares the performance of DeepBoost to other\n",
      "algorithms, including AdaBoost, Logistic Regression, and L1-norm regularized\n",
      "AdaBoost.  **Key findings:**  1. **Improved performance:** DeepBoost performs\n",
      "better than AdaBoost and LogReg on all datasets, including the UCI datasets and\n",
      "the MNIST dataset. 2. **Increased tree sizes:** DeepBoost selects trees of\n",
      "smaller size on average than the trees selected by AdaBoostL1 and LogRegL1. 3.\n",
      "**Better margin:** DeepBoost induces larger margins on the training set than\n",
      "AdaBoost (black) and AdaBoostL1 (blue).  **Limitations:**  1. **Complexity of\n",
      "hypothesis sets:** The paper notes that the hypothesis sets used in DeepBoost\n",
      "are complex, including very deep or complex hypotheses. 2. **Computational\n",
      "complexity:** The paper notes that the computational complexity of DeepBoost is\n",
      "higher than that of AdaBoost and LogReg. 3. **Limited generalizability:** The\n",
      "paper notes that the results of the experiments may not generalize to other\n",
      "datasets, and more work is needed to extend the results to other tasks.\n",
      "**Future work:**  1. **Extension to multiclass setting:** The paper notes that\n",
      "the results of the experiments are specifically for binary classification, and\n",
      "more work is needed to extend the results to multiclass classification. 2.\n",
      "**Extension to other loss functions:** The paper notes that the results of the\n",
      "experiments are specifically for logistic loss, and more work is needed to\n",
      "extend the results to other loss functions, such as hinge loss. 3.\n",
      "**Generalization to other algorithms:** The paper notes that the results of the\n",
      "experiments may not generalize to other algorithms, and more work is needed to\n",
      "extend the results to other algorithms.\n"
     ]
    }
   ],
   "source": [
    "# Local LLM_PATH\n",
    "LLM_PATH = \"/Users/sir/Downloads/HuggingFace/LLM/meta-Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# --- MODEL 1: THE \"GENERATOR\" (Llama 3.1 for summarizing) ---\n",
    "print(f\"Loading Generator: {LLM_PATH}\")\n",
    "\n",
    "# This line will now work correctly\n",
    "generator_model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLM_PATH, \n",
    "    device_map=DEVICE, # Automatically map to your M3 GPU\n",
    "    dtype=torch.float32, # Use float32 for M3\n",
    "    trust_remote_code=True\n",
    ")\n",
    "generator_tokenizer = AutoTokenizer.from_pretrained(LLM_PATH)\n",
    "\n",
    "# prompt construction\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Summarize the following text:\n",
    "\n",
    "{text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "input = generator_tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "# --- Tokenizer Configuration ---\n",
    "# Ensure pad_token_id is set before tokenizing or generating\n",
    "if generator_tokenizer.pad_token_id is None:\n",
    "    generator_tokenizer.pad_token_id = generator_tokenizer.eos_token_id\n",
    "\n",
    "# Define the terminators for Llama 3.1\n",
    "terminators = [\n",
    "    generator_tokenizer.eos_token_id,\n",
    "    generator_tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "# --- Generate text ---\n",
    "print(\"\\nGenerating summary with Llama-3.1-Instruct...\")\n",
    "with torch.no_grad():\n",
    "    outputs = generator_model.generate(\n",
    "        **input,\n",
    "        max_new_tokens=750,        \n",
    "        do_sample=True,\n",
    "        # Increase temperature slightly for stability on bfloat16/MPS\n",
    "        temperature=0.7,             # Standard, moderate randomness\n",
    "        top_p=0.9,                  \n",
    "        # Use the list of terminators for Llama 3.1\n",
    "        eos_token_id=terminators,    # Use the list of terminators\n",
    "        pad_token_id=generator_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# 1. Decode the raw text\n",
    "output_token_ids = outputs[0][len(input['input_ids'][0]):]\n",
    "raw_output = generator_tokenizer.decode(output_token_ids, skip_special_tokens=True)\n",
    "\n",
    "# 2. Clean the output\n",
    "response_only = raw_output.strip()\n",
    "\n",
    "# 3. Wrap and print the final, correct summary\n",
    "formatted_text = textwrap.fill(response_only, width=80)\n",
    "print(\"\\n--- GENERATED SUMMARY ---\")\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b2942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
